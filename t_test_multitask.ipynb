{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpNlqA-O-dBI",
        "outputId": "3347a01c-e5fd-40e9-d5a2-109772dd6d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TinyML-Contest-Solution'...\n",
            "remote: Enumerating objects: 30547, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 30547 (delta 0), reused 2 (delta 0), pack-reused 30545\u001b[K\n",
            "Receiving objects: 100% (30547/30547), 153.75 MiB | 11.99 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n",
            "Updating files: 100% (30513/30513), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/GATECH-EIC/TinyML-Contest-Solution.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd TinyML-Contest-Solution/Training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3Wzf4Ug-mzT",
        "outputId": "be546c94-f20f-489a-b071-3c7c2cf8cbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TinyML-Contest-Solution/Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"arritmia_cardiaca.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1kIePtG_yixpzcbjVl5mY7nwQkAytTe_V\n",
        "\"\"\"\n",
        "\n",
        "# Credits to https://towardsdatascience.com/multi-task-learning-for-computer-vision-classification-with-keras-36c52e6243d2\n",
        "\n",
        "# Imports\n",
        "print(\"start imports\")\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import time\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "from tensorflow import keras\n",
        "print(\"end imports\")\n",
        "\n",
        "\n",
        "# Custom stuff from https://github.com/GATECH-EIC/TinyML-Contest-Solution/blob/master/Training/select_model.py\n",
        "#from helpers.cosine_annealing import CosineAnnealingScheduler\n",
        "from swa.tfkeras import SWA\n",
        "\n",
        "\n",
        "\"\"\" Functions for loading data \"\"\"\n",
        "def txt_to_numpy(filename, row=1250):\n",
        "    file = open(filename)\n",
        "    lines = file.readlines()\n",
        "    datamat = np.arange(row, dtype=np.float)\n",
        "    row_count = 0\n",
        "    for line in lines:\n",
        "        line = line.strip().split(' ')\n",
        "        datamat[row_count] = line[0]\n",
        "        row_count += 1\n",
        "\n",
        "    return datamat\n",
        "\n",
        "\"\"\"\n",
        "AFb,Atrial Fibrillation\n",
        "AFt,Atrial Flutter\n",
        "SR,Sinus Rhythm\n",
        "SVT,Supraventricular Tachycardia\n",
        "VFb,Ventricular Fibrillation\n",
        "VFt,Ventricular Flutter\n",
        "VPD,Ventricular Premature Depolarizations\n",
        "VT,Ventricular Tachycardia\n",
        "\"\"\"\n",
        "def txt_to_disease_type(txt):\n",
        "    txt = txt.upper()\n",
        "    if txt == \"AFB\":\n",
        "      return [1, 0, 0, 0, 0, 0, 0, 0]\n",
        "    if txt == \"AFT\":\n",
        "      return [0, 1, 0, 0, 0, 0, 0, 0]\n",
        "    if txt == \"SR\":\n",
        "      return [0, 0, 1, 0, 0, 0, 0, 0]\n",
        "    if txt == \"SVT\":\n",
        "      return [0, 0, 0, 1, 0, 0, 0, 0]\n",
        "    if txt == \"VFB\":\n",
        "      return [0, 0, 0, 0, 1, 0, 0, 0]\n",
        "    if txt == \"VFT\":\n",
        "      return [0, 0, 0, 0, 0, 1, 0, 0]\n",
        "    if txt == \"VPD\":\n",
        "      return [0, 0, 0, 0, 0, 0, 1, 0]\n",
        "    if txt == \"VT\":\n",
        "      return [0, 0, 0, 0, 0, 0, 0, 1]\n",
        "    raise \"A string was not recognized as a valid input on txt_to_disease_type func!\"\n",
        "\n",
        "\"\"\"\n",
        "def read_data(csv_path, imgs_folder=\"./tinyml_contest_data_training\"):\n",
        "    x, y1, y2 = [], [], []\n",
        "    with open(csv_path, \"r\") as csv_file:\n",
        "      reader = csv.reader(csv_file)\n",
        "      next(reader)\n",
        "      for item in reader: # item[0] = label; item[1] = filename\n",
        "        x.append(txt_to_numpy(os.path.join(imgs_folder, item[1]), 1250))\n",
        "        y1.append([1, 0] if int(item[0]) == 0 else [0, 1]) # Label for life threat\n",
        "        y2.append(txt_to_disease_type(item[1].split(\"-\")[1]))\n",
        "    x, y1, y2 = sklearn.utils.shuffle(x, y1, y2)\n",
        "    return np.array(x), np.array(y1), np.array(y2)\n",
        "\"\"\"\n",
        "def read_data(csv_path, imgs_folder=\"./tinyml_contest_data_training\", augmentation=False, flip_peak=True, flip_time=True, add_noise=True): #, flip_peak=False, flip_time=False, add_noise=False):\n",
        "    x, y1, y2, y3, y4, y5 = [], [], [], [], [], []\n",
        "    print(\"passed here\")\n",
        "    with open(csv_path, \"r\") as csv_file:\n",
        "      reader = csv.reader(csv_file)\n",
        "      next(reader)\n",
        "      print(\"Reading data...\")\n",
        "      counter = 0\n",
        "      for item in reader: # item[0] = label; item[1] = filename\n",
        "        x.append(txt_to_numpy(os.path.join(imgs_folder, item[1]), 1250))\n",
        "        y1.append([1, 0] if int(item[0]) == 0 else [0, 1]) # Label for life threat\n",
        "        y2.append(txt_to_disease_type(item[1].split(\"-\")[1]))\n",
        "        counter +=1\n",
        "        if counter % 200 == 0:\n",
        "          print(f\"{counter} entries read...\")\n",
        "    x, y1, y2 = sklearn.utils.shuffle(x, y1, y2)\n",
        "    x = np.array(x)\n",
        "\n",
        "    # y3 creation\n",
        "    for sample in x:\n",
        "       y3.append(np.mean(sample))\n",
        "       stdeviation = np.std(sample)\n",
        "       y4.append(stdeviation)\n",
        "       y5.append(stdeviation ** 2)\n",
        "\n",
        "    if augmentation:\n",
        "      #x = x + np.random.normal(0, random.random()*np.amax(x)*0.05, (len(x), 1))\n",
        "\n",
        "      for i in range(len(x)):\n",
        "        flip_p = random.random()\n",
        "        flip_t = random.random()\n",
        "        if flip_p < 0.5 and flip_peak:\n",
        "          x[i] = -x[i]\n",
        "        if flip_t < 0.5 and flip_time:\n",
        "          x[i] = np.flip(x[i])\n",
        "        if add_noise:\n",
        "          print(f\"i={i}\")\n",
        "          max_peak = x[i].max() * 0.05\n",
        "          factor = random.random()\n",
        "        # factor = 1\n",
        "          noise = np.random.normal(0, factor * max_peak, x[0].shape)\n",
        "          x[i] = x[i] + noise\n",
        "    return x, np.array(y1), np.array(y2), np.array(y3), np.array(y4), np.array(y5)\n",
        "\n",
        "\n",
        "\"\"\" Loading data \"\"\"\n",
        "x_train, y_train_1, y_train_2, y_train_3, y_train_4, y_train_5 = read_data(\"./data_indices/train_indice.csv\", augmentation=False) #augmentation=True, flip_peak=True, flip_time=True, add_noise=True)\n",
        "x_test, y_test_1, y_test_2, y_test_3, y_test_4, y_test_5 = read_data(\"./data_indices/test_indice.csv\")\n",
        "print(\"Finished reading data!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR_On0rI-tCW",
        "outputId": "fde359af-beca-492e-d5c9-b88bf497d710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start imports\n",
            "end imports\n",
            "passed here\n",
            "Reading data...\n",
            "200 entries read...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-15a4b586a726>:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  datamat = np.arange(row, dtype=np.float)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 entries read...\n",
            "600 entries read...\n",
            "800 entries read...\n",
            "1000 entries read...\n",
            "1200 entries read...\n",
            "1400 entries read...\n",
            "1600 entries read...\n",
            "1800 entries read...\n",
            "2000 entries read...\n",
            "2200 entries read...\n",
            "2400 entries read...\n",
            "2600 entries read...\n",
            "2800 entries read...\n",
            "3000 entries read...\n",
            "3200 entries read...\n",
            "3400 entries read...\n",
            "3600 entries read...\n",
            "3800 entries read...\n",
            "4000 entries read...\n",
            "4200 entries read...\n",
            "4400 entries read...\n",
            "4600 entries read...\n",
            "4800 entries read...\n",
            "5000 entries read...\n",
            "5200 entries read...\n",
            "5400 entries read...\n",
            "5600 entries read...\n",
            "5800 entries read...\n",
            "6000 entries read...\n",
            "6200 entries read...\n",
            "6400 entries read...\n",
            "6600 entries read...\n",
            "6800 entries read...\n",
            "7000 entries read...\n",
            "7200 entries read...\n",
            "7400 entries read...\n",
            "7600 entries read...\n",
            "7800 entries read...\n",
            "8000 entries read...\n",
            "8200 entries read...\n",
            "8400 entries read...\n",
            "8600 entries read...\n",
            "8800 entries read...\n",
            "9000 entries read...\n",
            "9200 entries read...\n",
            "9400 entries read...\n",
            "9600 entries read...\n",
            "9800 entries read...\n",
            "10000 entries read...\n",
            "10200 entries read...\n",
            "10400 entries read...\n",
            "10600 entries read...\n",
            "10800 entries read...\n",
            "11000 entries read...\n",
            "11200 entries read...\n",
            "11400 entries read...\n",
            "11600 entries read...\n",
            "11800 entries read...\n",
            "12000 entries read...\n",
            "12200 entries read...\n",
            "12400 entries read...\n",
            "12600 entries read...\n",
            "12800 entries read...\n",
            "13000 entries read...\n",
            "13200 entries read...\n",
            "13400 entries read...\n",
            "13600 entries read...\n",
            "13800 entries read...\n",
            "14000 entries read...\n",
            "14200 entries read...\n",
            "14400 entries read...\n",
            "14600 entries read...\n",
            "14800 entries read...\n",
            "15000 entries read...\n",
            "15200 entries read...\n",
            "15400 entries read...\n",
            "15600 entries read...\n",
            "15800 entries read...\n",
            "16000 entries read...\n",
            "16200 entries read...\n",
            "16400 entries read...\n",
            "16600 entries read...\n",
            "16800 entries read...\n",
            "17000 entries read...\n",
            "17200 entries read...\n",
            "17400 entries read...\n",
            "17600 entries read...\n",
            "17800 entries read...\n",
            "18000 entries read...\n",
            "18200 entries read...\n",
            "18400 entries read...\n",
            "18600 entries read...\n",
            "18800 entries read...\n",
            "19000 entries read...\n",
            "19200 entries read...\n",
            "19400 entries read...\n",
            "19600 entries read...\n",
            "19800 entries read...\n",
            "20000 entries read...\n",
            "20200 entries read...\n",
            "20400 entries read...\n",
            "20600 entries read...\n",
            "20800 entries read...\n",
            "21000 entries read...\n",
            "21200 entries read...\n",
            "21400 entries read...\n",
            "21600 entries read...\n",
            "21800 entries read...\n",
            "22000 entries read...\n",
            "22200 entries read...\n",
            "22400 entries read...\n",
            "22600 entries read...\n",
            "22800 entries read...\n",
            "23000 entries read...\n",
            "23200 entries read...\n",
            "23400 entries read...\n",
            "23600 entries read...\n",
            "23800 entries read...\n",
            "24000 entries read...\n",
            "24200 entries read...\n",
            "24400 entries read...\n",
            "passed here\n",
            "Reading data...\n",
            "200 entries read...\n",
            "400 entries read...\n",
            "600 entries read...\n",
            "800 entries read...\n",
            "1000 entries read...\n",
            "1200 entries read...\n",
            "1400 entries read...\n",
            "1600 entries read...\n",
            "1800 entries read...\n",
            "2000 entries read...\n",
            "2200 entries read...\n",
            "2400 entries read...\n",
            "2600 entries read...\n",
            "2800 entries read...\n",
            "3000 entries read...\n",
            "3200 entries read...\n",
            "3400 entries read...\n",
            "3600 entries read...\n",
            "3800 entries read...\n",
            "4000 entries read...\n",
            "4200 entries read...\n",
            "4400 entries read...\n",
            "4600 entries read...\n",
            "4800 entries read...\n",
            "5000 entries read...\n",
            "5200 entries read...\n",
            "5400 entries read...\n",
            "5600 entries read...\n",
            "Finished reading data!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "yNawcpvQH5ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, _, y_train_1, _, = train_test_split(x_train, y_train_1, train_size=0.4)"
      ],
      "metadata": {
        "id": "sv0C9ZGqMUFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying to improve multitask!!!\n",
        "\n",
        "#best result --> no augmentation\n",
        "\n",
        "\"\"\" Functions for creating, compiling and training model\"\"\"\n",
        "\n",
        "# Architecture:\n",
        "# Main branch\n",
        "# Branch1 => Decides wheter life threatening (VF or VT style) or not (SR and others)\n",
        "# Branch2 => Classify the input\n",
        "\n",
        "\n",
        "# labels,Rhythm\n",
        "# AFb,Atrial Fibrillation\n",
        "# AFt,Atrial Flutter\n",
        "# SR,Sinus Rhythm\n",
        "# SVT,Supraventricular Tachycardia\n",
        "# VFb,Ventricular Fibrillation\n",
        "# VFt,Ventricular Flutter\n",
        "# VPD,Ventricular Premature Depolarizations\n",
        "# VT,Ventricular Tachycardia\n",
        "\n",
        "\n",
        "def gen_model():\n",
        "    inputs = keras.layers.Input(shape=(1250, 1), name='input')\n",
        "\n",
        "    main_branch = keras.layers.Conv1D(filters=3, kernel_size=6, strides=2, activation=\"relu\") (inputs)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Conv1D(filters=5, kernel_size=5, strides=2,  activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Conv1D(filters=10, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Conv1D(filters=20, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Conv1D(filters=20, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=32, kernel_size=1, strides=32, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Flatten() (main_branch)\n",
        "    main_branch = keras.layers.Dropout(0.5) (main_branch)\n",
        "    #main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.Dropout(0.1) (main_branch)\n",
        "    #main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.Dropout(0.1) (main_branch)\n",
        "    main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "\n",
        "    #branch1 = keras.layers.Dense(128, activation=\"relu\") (branch1)\n",
        "    #branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    #branch1 = keras.layers.Dense(128, activation=\"relu\") (branch1)\n",
        "    #branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    #branch1 = keras.layers.Dropout(0.2) (branch1)\n",
        "\n",
        "    # Decides wheter life threatening (VF or VT style) or not (SR and others)\n",
        "    branch1 = keras.layers.Dense(2, activation=\"softmax\", name='task_1_output') (main_branch)\n",
        "\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (main_branch)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (branch2)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (branch2)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dropout(0.2) (branch2)\n",
        "\n",
        "    # Classify the input\n",
        "    branch2 = keras.layers.Dense(8, activation=\"softmax\", name='task_2_output') (main_branch)\n",
        "\n",
        "    # mean\n",
        "    branch3 = keras.layers.Dense(1, activation=\"relu\", name='task_3_output') (main_branch)\n",
        "\n",
        "    ## std\n",
        "    #branch4 = keras.layers.Dense(1, activation=\"relu\", name='task_4_output') (main_branch)\n",
        "#\n",
        "    ## var\n",
        "    #branch5 = keras.layers.Dense(1, activation=\"relu\", name='task_5_output') (main_branch)\n",
        "\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = [branch1, branch2, branch3,]) #branch4, branch5])\n",
        "\n",
        "    return model\n",
        "\n",
        "tf.keras.utils.plot_model(gen_model(), to_file='model_diagram.png', show_layer_activations=True,)\n",
        "\n",
        "# loss_weight -> [0, 1]\n",
        "# the weight for the second task is calculated by '1 - loss_weight'\n",
        "def compile_model(model, loss_weight1, loss_weight2, loss_weight3, loss_weight4, loss_weight5):\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0002),\n",
        "                  loss={'task_1_output': 'binary_crossentropy',\n",
        "                        'task_2_output': 'categorical_crossentropy',\n",
        "                        'task_3_output': 'mse',\n",
        "                        #'task_4_output': 'mse',\n",
        "                        #'task_5_output': 'mse'\n",
        "                        },\n",
        "                  loss_weights={'task_1_output': loss_weight1,\n",
        "                                'task_2_output': loss_weight2,\n",
        "                                'task_3_output': loss_weight3,\n",
        "                                #'task_4_output': loss_weight4,\n",
        "                                #'task_5_output': loss_weight5\n",
        "                                },\n",
        "                  metrics={'task_1_output' : [\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
        "                           'task_2_output' : [\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
        "                           'task_3_output' : \"mse\",\n",
        "                           #'task_4_output' : \"mse\",\n",
        "                           #'task_5_output' : \"mse\"\n",
        "                           })\n",
        "    return model\n",
        "\n",
        "def fit_batch(gamma_values, epochs=30, batch_size=32, save_models=False, models_dir=\"./trained_models\", verbose=0):\n",
        "\n",
        "    history = list()\n",
        "    trained_models = list()\n",
        "    test_scores = list()\n",
        "\n",
        "    start_epoch = 10\n",
        "    swa = SWA(start_epoch=start_epoch,\n",
        "          lr_schedule='cyclic',\n",
        "          swa_lr=0.0001,\n",
        "          swa_lr2=0.0005,\n",
        "          swa_freq=5,\n",
        "          batch_size=batch_size,\n",
        "          verbose=1)\n",
        "\n",
        "    if save_models and not os.path.isdir(models_dir):\n",
        "      os.mkdir(models_dir)\n",
        "\n",
        "    print('Starting training on batch of models for gamma values ', gamma_values, '\\n\\n')\n",
        "\n",
        "    for i, gamma in enumerate(gamma_values):\n",
        "\n",
        "        print('Training model for gamma equal to ', gamma)\n",
        "        model = gen_model()\n",
        "        model = compile_model(model, gamma[0], gamma[1], gamma[2], gamma[3], gamma[4])\n",
        "        start = time.time()\n",
        "        model_history = model.fit({'input': x_train},\n",
        "                            {'task_1_output': y_train_1, 'task_2_output': y_train_2, 'task_3_output': y_train_3,\n",
        "                             #'task_4_output': y_train_4, 'task_5_output': y_train_5\n",
        "                             },\n",
        "                            epochs=epochs, batch_size=batch_size, verbose=verbose) # callbacks=[swa],\n",
        "        print(f'Training time: {time.time() - start}\\n')\n",
        "        history.append(model_history)\n",
        "        trained_models.append(model)\n",
        "        if save_models:\n",
        "          model.save(os.path.join(models_dir, f\"{i}th-model\"))\n",
        "\n",
        "        test_score = model.evaluate({'input': x_test}, {'task_1_output': y_test_1, 'task_2_output': y_test_2, 'task_3_output': y_test_3,\n",
        "                                                        #'task_4_output': y_test_4, 'task_5_output': y_test_5\n",
        "                                                        })\n",
        "        for metric, result in zip(model.metrics_names, test_score):\n",
        "          print(f\"{metric}: {result}\")\n",
        "\n",
        "        test_scores.append(test_score)\n",
        "\n",
        "    return history, trained_models, test_scores\n",
        "\n",
        "def plot_multitask_accuracies(gammas, training_history):\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for history in training_history:\n",
        "\n",
        "        print(f'\\nPlotting Accuracy/Precision/Recall vs Epochs for value of gamma number {gammas[counter]}\\n')\n",
        "        plt.plot(range(len(history.history['task_1_output_accuracy'])), history.history['task_1_output_accuracy'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_accuracy'])), history.history['task_2_output_accuracy'], c='b', label='Task 2')\n",
        "        plt.plot(range(len(history.history['task_1_output_precision'])), history.history['task_1_output_precision'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_precision'])), history.history['task_2_output_precision'], c='b', label='Task 2')\n",
        "        plt.plot(range(len(history.history['task_1_output_recall'])), history.history['task_1_output_recall'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_recall'])), history.history['task_2_output_recall'], c='b', label='Task 2')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        counter += 1\n",
        "\n",
        "\"\"\"Actually training the model\"\"\"\n",
        "#gamma_values = [ [0.2, 0.2, 0.2, 0.2, 0.2],\n",
        "#                [0.8, 0.1, 0.0333, 0.0333, 0.0333],\n",
        "#                [0.5, 0.125, 0.125, 0.125, 0.125],\n",
        "#                [0.5, 0.2, 0.1, 0.1, 0.1],\n",
        "#                [0.6, 0.3, 0.033, 0.033, 0.033]]\n",
        "\n",
        "gamma_values = [  [0.5, 0.25, 0.25, 0, 0],\n",
        "                  [0.6, 0.2, 0.2, 0, 0],\n",
        "                  [0.7, 0.2, 0.1, 0, 0],\n",
        "                  [0.8, 0.1, 0.1, 0, 0],]\n",
        "\n",
        "history, trained_models, _ = fit_batch(gamma_values, epochs=20, save_models=True, models_dir=\"./trained_models_sixth_augmentation\", verbose=1)\n"
      ],
      "metadata": {
        "id": "ky-gD2z2-3tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying to improve multitask!!!\n",
        "\n",
        "#best result --> no augmentation\n",
        "\n",
        "\"\"\" Functions for creating, compiling and training model\"\"\"\n",
        "\n",
        "# Architecture:\n",
        "# Main branch\n",
        "# Branch1 => Decides wheter life threatening (VF or VT style) or not (SR and others)\n",
        "# Branch2 => Classify the input\n",
        "\n",
        "\n",
        "# labels,Rhythm\n",
        "# AFb,Atrial Fibrillation\n",
        "# AFt,Atrial Flutter\n",
        "# SR,Sinus Rhythm\n",
        "# SVT,Supraventricular Tachycardia\n",
        "# VFb,Ventricular Fibrillation\n",
        "# VFt,Ventricular Flutter\n",
        "# VPD,Ventricular Premature Depolarizations\n",
        "# VT,Ventricular Tachycardia\n",
        "\n",
        "\n",
        "def gen_model():\n",
        "    inputs = keras.layers.Input(shape=(1250, 1), name='input')\n",
        "\n",
        "    main_branch = keras.layers.Conv1D(filters=3, kernel_size=6, strides=2, activation=\"relu\") (inputs)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Conv1D(filters=5, kernel_size=5, strides=2,  activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Conv1D(filters=10, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Conv1D(filters=20, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Conv1D(filters=20, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=32, kernel_size=1, strides=32, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Flatten() (main_branch)\n",
        "    main_branch = keras.layers.Dropout(0.5) (main_branch)\n",
        "    #main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.Dropout(0.1) (main_branch)\n",
        "    #main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.Dropout(0.1) (main_branch)\n",
        "    main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "\n",
        "    #branch1 = keras.layers.Dense(128, activation=\"relu\") (branch1)\n",
        "    #branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    #branch1 = keras.layers.Dense(128, activation=\"relu\") (branch1)\n",
        "    #branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    #branch1 = keras.layers.Dropout(0.2) (branch1)\n",
        "\n",
        "    # Decides wheter life threatening (VF or VT style) or not (SR and others)\n",
        "    branch1 = keras.layers.Dense(2, activation=\"softmax\", name='task_1_output') (main_branch)\n",
        "\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (main_branch)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (branch2)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (branch2)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dropout(0.2) (branch2)\n",
        "\n",
        "    # Classify the input\n",
        "    branch2 = keras.layers.Dense(8, activation=\"softmax\", name='task_2_output') (main_branch)\n",
        "\n",
        "    # mean\n",
        "    branch3 = keras.layers.Dense(1, activation=\"relu\", name='task_3_output') (main_branch)\n",
        "\n",
        "    ## std\n",
        "    #branch4 = keras.layers.Dense(1, activation=\"relu\", name='task_4_output') (main_branch)\n",
        "#\n",
        "    ## var\n",
        "    #branch5 = keras.layers.Dense(1, activation=\"relu\", name='task_5_output') (main_branch)\n",
        "\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = [branch1, branch2, branch3,]) #branch4, branch5])\n",
        "\n",
        "    return model\n",
        "\n",
        "# loss_weight -> [0, 1]\n",
        "# the weight for the second task is calculated by '1 - loss_weight'\n",
        "def compile_model(model, loss_weight1, loss_weight2, loss_weight3, loss_weight4, loss_weight5):\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0002),\n",
        "                  loss={'task_1_output': 'binary_crossentropy',\n",
        "                        'task_2_output': 'categorical_crossentropy',\n",
        "                        'task_3_output': 'mse',\n",
        "                        #'task_4_output': 'mse',\n",
        "                        #'task_5_output': 'mse'\n",
        "                        },\n",
        "                  loss_weights={'task_1_output': loss_weight1,\n",
        "                                'task_2_output': loss_weight2,\n",
        "                                'task_3_output': loss_weight3,\n",
        "                                #'task_4_output': loss_weight4,\n",
        "                                #'task_5_output': loss_weight5\n",
        "                                },\n",
        "                  metrics={'task_1_output' : [\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
        "                           'task_2_output' : [\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
        "                           'task_3_output' : \"mse\",\n",
        "                           #'task_4_output' : \"mse\",\n",
        "                           #'task_5_output' : \"mse\"\n",
        "                           })\n",
        "    return model\n",
        "\n",
        "def fit_batch(gamma_values, epochs=30, batch_size=32, save_models=False, models_dir=\"./trained_models\", verbose=0):\n",
        "\n",
        "    history = list()\n",
        "    trained_models = list()\n",
        "    test_scores = list()\n",
        "\n",
        "    start_epoch = 10\n",
        "    swa = SWA(start_epoch=start_epoch,\n",
        "          lr_schedule='cyclic',\n",
        "          swa_lr=0.0001,\n",
        "          swa_lr2=0.0005,\n",
        "          swa_freq=5,\n",
        "          batch_size=batch_size,\n",
        "          verbose=1)\n",
        "\n",
        "    if save_models and not os.path.isdir(models_dir):\n",
        "      os.mkdir(models_dir)\n",
        "\n",
        "    print('Starting training on batch of models for gamma values ', gamma_values, '\\n\\n')\n",
        "\n",
        "    for i, gamma in enumerate(gamma_values):\n",
        "\n",
        "        print('Training model for gamma equal to ', gamma)\n",
        "        model = gen_model()\n",
        "        model = compile_model(model, gamma[0], gamma[1], gamma[2], gamma[3], gamma[4])\n",
        "        start = time.time()\n",
        "        model_history = model.fit({'input': x_train},\n",
        "                            {'task_1_output': y_train_1, 'task_2_output': y_train_2, 'task_3_output': y_train_3,\n",
        "                             #'task_4_output': y_train_4, 'task_5_output': y_train_5\n",
        "                             },\n",
        "                            epochs=epochs, batch_size=batch_size, verbose=verbose) # callbacks=[swa],\n",
        "        print(f'Training time: {time.time() - start}\\n')\n",
        "        history.append(model_history)\n",
        "        trained_models.append(model)\n",
        "        if save_models:\n",
        "          model.save(os.path.join(models_dir, f\"{i}th-model\"))\n",
        "\n",
        "        test_score = model.evaluate({'input': x_test}, {'task_1_output': y_test_1, 'task_2_output': y_test_2, 'task_3_output': y_test_3,\n",
        "                                                        #'task_4_output': y_test_4, 'task_5_output': y_test_5\n",
        "                                                        })\n",
        "        for metric, result in zip(model.metrics_names, test_score):\n",
        "          print(f\"{metric}: {result}\")\n",
        "\n",
        "        test_scores.append(test_score)\n",
        "\n",
        "    return history, trained_models, test_scores\n",
        "\n",
        "def plot_multitask_accuracies(gammas, training_history):\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for history in training_history:\n",
        "\n",
        "        print(f'\\nPlotting Accuracy/Precision/Recall vs Epochs for value of gamma number {gammas[counter]}\\n')\n",
        "        plt.plot(range(len(history.history['task_1_output_accuracy'])), history.history['task_1_output_accuracy'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_accuracy'])), history.history['task_2_output_accuracy'], c='b', label='Task 2')\n",
        "        plt.plot(range(len(history.history['task_1_output_precision'])), history.history['task_1_output_precision'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_precision'])), history.history['task_2_output_precision'], c='b', label='Task 2')\n",
        "        plt.plot(range(len(history.history['task_1_output_recall'])), history.history['task_1_output_recall'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_recall'])), history.history['task_2_output_recall'], c='b', label='Task 2')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        counter += 1\n",
        "\n",
        "\"\"\"Actually training the model\"\"\"\n",
        "#gamma_values = [ [0.2, 0.2, 0.2, 0.2, 0.2],\n",
        "#                [0.8, 0.1, 0.0333, 0.0333, 0.0333],\n",
        "#                [0.5, 0.125, 0.125, 0.125, 0.125],\n",
        "#                [0.5, 0.2, 0.1, 0.1, 0.1],\n",
        "#                [0.6, 0.3, 0.033, 0.033, 0.033]]\n",
        "\n",
        "gamma_values = [ [0.8, 0.2, 0, 0, 0],]\n",
        "\n",
        "for _ in range(20):\n",
        "  history, trained_models, _ = fit_batch(gamma_values, epochs=20, save_models=True, models_dir=\"./trained_models_sixth_augmentation\", verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOYuEPvbjxgw",
        "outputId": "4ab5913b-1fe4-43b3-d260-3f2c4c51a367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 183.06656885147095\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 5ms/step - loss: 0.4407 - task_1_output_loss: 0.3216 - task_2_output_loss: 0.9170 - task_3_output_loss: 0.8154 - task_1_output_accuracy: 0.9573 - task_1_output_precision_88: 0.9573 - task_1_output_recall_88: 0.9573 - task_2_output_accuracy: 0.8341 - task_2_output_precision_89: 0.8387 - task_2_output_recall_89: 0.8302 - task_3_output_mse: 0.8154\n",
            "loss: 0.44065260887145996\n",
            "task_1_output_loss: 0.3215768337249756\n",
            "task_2_output_loss: 0.916955828666687\n",
            "task_3_output_loss: 0.8154197335243225\n",
            "task_1_output_accuracy: 0.9573333263397217\n",
            "task_1_output_precision_88: 0.9573333263397217\n",
            "task_1_output_recall_88: 0.9573333263397217\n",
            "task_2_output_accuracy: 0.8341333270072937\n",
            "task_2_output_precision_89: 0.8387212753295898\n",
            "task_2_output_recall_89: 0.8302222490310669\n",
            "task_3_output_mse: 0.8154197335243225\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 185.30848813056946\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 5ms/step - loss: 0.3907 - task_1_output_loss: 0.2793 - task_2_output_loss: 0.8362 - task_3_output_loss: 1.0999 - task_1_output_accuracy: 0.9582 - task_1_output_precision_90: 0.9582 - task_1_output_recall_90: 0.9582 - task_2_output_accuracy: 0.8231 - task_2_output_precision_91: 0.8285 - task_2_output_recall_91: 0.8169 - task_3_output_mse: 1.0999\n",
            "loss: 0.39068564772605896\n",
            "task_1_output_loss: 0.2793075740337372\n",
            "task_2_output_loss: 0.836198091506958\n",
            "task_3_output_loss: 1.0999072790145874\n",
            "task_1_output_accuracy: 0.9582222104072571\n",
            "task_1_output_precision_90: 0.9582222104072571\n",
            "task_1_output_recall_90: 0.9582222104072571\n",
            "task_2_output_accuracy: 0.8231111168861389\n",
            "task_2_output_precision_91: 0.8285250663757324\n",
            "task_2_output_recall_91: 0.8168888688087463\n",
            "task_3_output_mse: 1.0999072790145874\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 206.3852186203003\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.4333 - task_1_output_loss: 0.3262 - task_2_output_loss: 0.8614 - task_3_output_loss: 0.3196 - task_1_output_accuracy: 0.9532 - task_1_output_precision_92: 0.9532 - task_1_output_recall_92: 0.9532 - task_2_output_accuracy: 0.8263 - task_2_output_precision_93: 0.8379 - task_2_output_recall_93: 0.8105 - task_3_output_mse: 0.3196\n",
            "loss: 0.4332614243030548\n",
            "task_1_output_loss: 0.3262348473072052\n",
            "task_2_output_loss: 0.8613669872283936\n",
            "task_3_output_loss: 0.31957098841667175\n",
            "task_1_output_accuracy: 0.9532444477081299\n",
            "task_1_output_precision_92: 0.9532444477081299\n",
            "task_1_output_recall_92: 0.9532444477081299\n",
            "task_2_output_accuracy: 0.8263111114501953\n",
            "task_2_output_precision_93: 0.8378974199295044\n",
            "task_2_output_recall_93: 0.8104888796806335\n",
            "task_3_output_mse: 0.31957098841667175\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 205.64003109931946\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.3708 - task_1_output_loss: 0.2620 - task_2_output_loss: 0.8061 - task_3_output_loss: 0.3874 - task_1_output_accuracy: 0.9589 - task_1_output_precision_94: 0.9589 - task_1_output_recall_94: 0.9589 - task_2_output_accuracy: 0.8334 - task_2_output_precision_95: 0.8402 - task_2_output_recall_95: 0.8251 - task_3_output_mse: 0.3874\n",
            "loss: 0.370828241109848\n",
            "task_1_output_loss: 0.2620190680027008\n",
            "task_2_output_loss: 0.8060644865036011\n",
            "task_3_output_loss: 0.3874266445636749\n",
            "task_1_output_accuracy: 0.9589333534240723\n",
            "task_1_output_precision_94: 0.9589333534240723\n",
            "task_1_output_recall_94: 0.9589333534240723\n",
            "task_2_output_accuracy: 0.8334222435951233\n",
            "task_2_output_precision_95: 0.8401520848274231\n",
            "task_2_output_recall_95: 0.8250666856765747\n",
            "task_3_output_mse: 0.3874266445636749\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 206.1249213218689\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 8ms/step - loss: 0.4172 - task_1_output_loss: 0.3036 - task_2_output_loss: 0.8717 - task_3_output_loss: 1.3797 - task_1_output_accuracy: 0.9620 - task_1_output_precision_96: 0.9620 - task_1_output_recall_96: 0.9620 - task_2_output_accuracy: 0.8260 - task_2_output_precision_97: 0.8337 - task_2_output_recall_97: 0.8121 - task_3_output_mse: 1.3797\n",
            "loss: 0.4172452688217163\n",
            "task_1_output_loss: 0.30364081263542175\n",
            "task_2_output_loss: 0.8716632723808289\n",
            "task_3_output_loss: 1.3797204494476318\n",
            "task_1_output_accuracy: 0.9619555473327637\n",
            "task_1_output_precision_96: 0.9619555473327637\n",
            "task_1_output_recall_96: 0.9619555473327637\n",
            "task_2_output_accuracy: 0.8259555697441101\n",
            "task_2_output_precision_97: 0.8337287902832031\n",
            "task_2_output_recall_97: 0.8120889067649841\n",
            "task_3_output_mse: 1.3797204494476318\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 206.44730973243713\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.3649 - task_1_output_loss: 0.2313 - task_2_output_loss: 0.8993 - task_3_output_loss: 0.3100 - task_1_output_accuracy: 0.9564 - task_1_output_precision_98: 0.9564 - task_1_output_recall_98: 0.9564 - task_2_output_accuracy: 0.8071 - task_2_output_precision_99: 0.8125 - task_2_output_recall_99: 0.8020 - task_3_output_mse: 0.3100\n",
            "loss: 0.3649197816848755\n",
            "task_1_output_loss: 0.23131848871707916\n",
            "task_2_output_loss: 0.8993252515792847\n",
            "task_3_output_loss: 0.3100317418575287\n",
            "task_1_output_accuracy: 0.9564444422721863\n",
            "task_1_output_precision_98: 0.9564444422721863\n",
            "task_1_output_recall_98: 0.9564444422721863\n",
            "task_2_output_accuracy: 0.8071110844612122\n",
            "task_2_output_precision_99: 0.8125\n",
            "task_2_output_recall_99: 0.8019555807113647\n",
            "task_3_output_mse: 0.3100317418575287\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 181.86069297790527\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.3922 - task_1_output_loss: 0.2876 - task_2_output_loss: 0.8108 - task_3_output_loss: 0.9272 - task_1_output_accuracy: 0.9605 - task_1_output_precision_100: 0.9605 - task_1_output_recall_100: 0.9605 - task_2_output_accuracy: 0.8226 - task_2_output_precision_101: 0.8337 - task_2_output_recall_101: 0.8148 - task_3_output_mse: 0.9272\n",
            "loss: 0.3922181725502014\n",
            "task_1_output_loss: 0.28757479786872864\n",
            "task_2_output_loss: 0.8107919096946716\n",
            "task_3_output_loss: 0.9271742105484009\n",
            "task_1_output_accuracy: 0.9605333209037781\n",
            "task_1_output_precision_100: 0.9605333209037781\n",
            "task_1_output_recall_100: 0.9605333209037781\n",
            "task_2_output_accuracy: 0.8225777745246887\n",
            "task_2_output_precision_101: 0.8337274789810181\n",
            "task_2_output_recall_101: 0.8147555589675903\n",
            "task_3_output_mse: 0.9271742105484009\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 206.40304827690125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.3783 - task_1_output_loss: 0.2484 - task_2_output_loss: 0.8976 - task_3_output_loss: 0.8530 - task_1_output_accuracy: 0.9627 - task_1_output_precision_102: 0.9627 - task_1_output_recall_102: 0.9627 - task_2_output_accuracy: 0.8213 - task_2_output_precision_103: 0.8274 - task_2_output_recall_103: 0.8192 - task_3_output_mse: 0.8530\n",
            "loss: 0.3782501816749573\n",
            "task_1_output_loss: 0.24841509759426117\n",
            "task_2_output_loss: 0.8975900411605835\n",
            "task_3_output_loss: 0.8529779314994812\n",
            "task_1_output_accuracy: 0.9626666903495789\n",
            "task_1_output_precision_102: 0.9626666903495789\n",
            "task_1_output_recall_102: 0.9626666903495789\n",
            "task_2_output_accuracy: 0.8213333487510681\n",
            "task_2_output_precision_103: 0.8274375796318054\n",
            "task_2_output_recall_103: 0.8191999793052673\n",
            "task_3_output_mse: 0.8529779314994812\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 181.0202715396881\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3903 - task_1_output_loss: 0.2734 - task_2_output_loss: 0.8577 - task_3_output_loss: 0.3241 - task_1_output_accuracy: 0.9497 - task_1_output_precision_104: 0.9497 - task_1_output_recall_104: 0.9497 - task_2_output_accuracy: 0.8169 - task_2_output_precision_105: 0.8264 - task_2_output_recall_105: 0.8075 - task_3_output_mse: 0.3241\n",
            "loss: 0.3902652859687805\n",
            "task_1_output_loss: 0.2734065651893616\n",
            "task_2_output_loss: 0.8577007055282593\n",
            "task_3_output_loss: 0.3240935206413269\n",
            "task_1_output_accuracy: 0.9496889114379883\n",
            "task_1_output_precision_104: 0.9496889114379883\n",
            "task_1_output_recall_104: 0.9496889114379883\n",
            "task_2_output_accuracy: 0.8168888688087463\n",
            "task_2_output_precision_105: 0.8264192342758179\n",
            "task_2_output_recall_105: 0.8074666857719421\n",
            "task_3_output_mse: 0.3240935206413269\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 207.21113753318787\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 8ms/step - loss: 0.3919 - task_1_output_loss: 0.2818 - task_2_output_loss: 0.8322 - task_3_output_loss: 0.6904 - task_1_output_accuracy: 0.9593 - task_1_output_precision_106: 0.9593 - task_1_output_recall_106: 0.9593 - task_2_output_accuracy: 0.8356 - task_2_output_precision_107: 0.8455 - task_2_output_recall_107: 0.8258 - task_3_output_mse: 0.6904\n",
            "loss: 0.3918967545032501\n",
            "task_1_output_loss: 0.2818089425563812\n",
            "task_2_output_loss: 0.8322473764419556\n",
            "task_3_output_loss: 0.6903631687164307\n",
            "task_1_output_accuracy: 0.9592888951301575\n",
            "task_1_output_precision_106: 0.9592888951301575\n",
            "task_1_output_recall_106: 0.9592888951301575\n",
            "task_2_output_accuracy: 0.8355555534362793\n",
            "task_2_output_precision_107: 0.8454678058624268\n",
            "task_2_output_recall_107: 0.8257777690887451\n",
            "task_3_output_mse: 0.6903631687164307\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 180.48658442497253\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.3864 - task_1_output_loss: 0.2754 - task_2_output_loss: 0.8304 - task_3_output_loss: 0.4765 - task_1_output_accuracy: 0.9513 - task_1_output_precision_108: 0.9513 - task_1_output_recall_108: 0.9513 - task_2_output_accuracy: 0.8172 - task_2_output_precision_109: 0.8253 - task_2_output_recall_109: 0.8103 - task_3_output_mse: 0.4765\n",
            "loss: 0.3864133656024933\n",
            "task_1_output_loss: 0.2754075825214386\n",
            "task_2_output_loss: 0.8304364681243896\n",
            "task_3_output_loss: 0.47650590538978577\n",
            "task_1_output_accuracy: 0.9512888789176941\n",
            "task_1_output_precision_108: 0.9512888789176941\n",
            "task_1_output_recall_108: 0.9512888789176941\n",
            "task_2_output_accuracy: 0.8172444701194763\n",
            "task_2_output_precision_109: 0.8252761363983154\n",
            "task_2_output_recall_109: 0.8103111386299133\n",
            "task_3_output_mse: 0.47650590538978577\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 181.60402965545654\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 5ms/step - loss: 0.3563 - task_1_output_loss: 0.2419 - task_2_output_loss: 0.8139 - task_3_output_loss: 0.8361 - task_1_output_accuracy: 0.9548 - task_1_output_precision_110: 0.9548 - task_1_output_recall_110: 0.9548 - task_2_output_accuracy: 0.8176 - task_2_output_precision_111: 0.8228 - task_2_output_recall_111: 0.8130 - task_3_output_mse: 0.8361\n",
            "loss: 0.356285035610199\n",
            "task_1_output_loss: 0.24188585579395294\n",
            "task_2_output_loss: 0.8138812780380249\n",
            "task_3_output_loss: 0.8360597491264343\n",
            "task_1_output_accuracy: 0.9548444151878357\n",
            "task_1_output_precision_110: 0.9548444151878357\n",
            "task_1_output_recall_110: 0.9548444151878357\n",
            "task_2_output_accuracy: 0.8176000118255615\n",
            "task_2_output_precision_111: 0.8227779865264893\n",
            "task_2_output_recall_111: 0.8129777908325195\n",
            "task_3_output_mse: 0.8360597491264343\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 206.366849899292\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 5ms/step - loss: 0.4001 - task_1_output_loss: 0.2797 - task_2_output_loss: 0.8815 - task_3_output_loss: 0.8114 - task_1_output_accuracy: 0.9509 - task_1_output_precision_112: 0.9509 - task_1_output_recall_112: 0.9509 - task_2_output_accuracy: 0.8092 - task_2_output_precision_113: 0.8164 - task_2_output_recall_113: 0.8007 - task_3_output_mse: 0.8114\n",
            "loss: 0.4000617563724518\n",
            "task_1_output_loss: 0.27971166372299194\n",
            "task_2_output_loss: 0.8814619183540344\n",
            "task_3_output_loss: 0.8114184141159058\n",
            "task_1_output_accuracy: 0.9509333372116089\n",
            "task_1_output_precision_112: 0.9509333372116089\n",
            "task_1_output_recall_112: 0.9509333372116089\n",
            "task_2_output_accuracy: 0.8092444539070129\n",
            "task_2_output_precision_113: 0.8163857460021973\n",
            "task_2_output_recall_113: 0.8007110953330994\n",
            "task_3_output_mse: 0.8114184141159058\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 182.8126027584076\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.3938 - task_1_output_loss: 0.2737 - task_2_output_loss: 0.8742 - task_3_output_loss: 0.7258 - task_1_output_accuracy: 0.9541 - task_1_output_precision_114: 0.9541 - task_1_output_recall_114: 0.9541 - task_2_output_accuracy: 0.8208 - task_2_output_precision_115: 0.8275 - task_2_output_recall_115: 0.8133 - task_3_output_mse: 0.7258\n",
            "loss: 0.3937901556491852\n",
            "task_1_output_loss: 0.2736819386482239\n",
            "task_2_output_loss: 0.8742231130599976\n",
            "task_3_output_loss: 0.725774884223938\n",
            "task_1_output_accuracy: 0.9541333317756653\n",
            "task_1_output_precision_114: 0.9541333317756653\n",
            "task_1_output_recall_114: 0.9541333317756653\n",
            "task_2_output_accuracy: 0.8208000063896179\n",
            "task_2_output_precision_115: 0.8274552226066589\n",
            "task_2_output_recall_115: 0.8133333325386047\n",
            "task_3_output_mse: 0.725774884223938\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 205.86853003501892\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 7ms/step - loss: 0.4171 - task_1_output_loss: 0.2947 - task_2_output_loss: 0.9065 - task_3_output_loss: 0.2118 - task_1_output_accuracy: 0.9580 - task_1_output_precision_116: 0.9580 - task_1_output_recall_116: 0.9580 - task_2_output_accuracy: 0.8283 - task_2_output_precision_117: 0.8387 - task_2_output_recall_117: 0.8219 - task_3_output_mse: 0.2118\n",
            "loss: 0.4170650541782379\n",
            "task_1_output_loss: 0.29469582438468933\n",
            "task_2_output_loss: 0.9065421223640442\n",
            "task_3_output_loss: 0.21176347136497498\n",
            "task_1_output_accuracy: 0.9580444693565369\n",
            "task_1_output_precision_116: 0.9580444693565369\n",
            "task_1_output_recall_116: 0.9580444693565369\n",
            "task_2_output_accuracy: 0.8282666802406311\n",
            "task_2_output_precision_117: 0.8387155532836914\n",
            "task_2_output_recall_117: 0.8218666911125183\n",
            "task_3_output_mse: 0.21176347136497498\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 206.0444519519806\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.3823 - task_1_output_loss: 0.2723 - task_2_output_loss: 0.8223 - task_3_output_loss: 0.8219 - task_1_output_accuracy: 0.9529 - task_1_output_precision_118: 0.9529 - task_1_output_recall_118: 0.9529 - task_2_output_accuracy: 0.8212 - task_2_output_precision_119: 0.8304 - task_2_output_recall_119: 0.8137 - task_3_output_mse: 0.8219\n",
            "loss: 0.38233041763305664\n",
            "task_1_output_loss: 0.27234143018722534\n",
            "task_2_output_loss: 0.8222869634628296\n",
            "task_3_output_loss: 0.8219249844551086\n",
            "task_1_output_accuracy: 0.9528889060020447\n",
            "task_1_output_precision_118: 0.9528889060020447\n",
            "task_1_output_recall_118: 0.9528889060020447\n",
            "task_2_output_accuracy: 0.8211555480957031\n",
            "task_2_output_precision_119: 0.8303701281547546\n",
            "task_2_output_recall_119: 0.8136888742446899\n",
            "task_3_output_mse: 0.8219249844551086\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 206.36462211608887\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.3684 - task_1_output_loss: 0.2587 - task_2_output_loss: 0.8070 - task_3_output_loss: 0.4890 - task_1_output_accuracy: 0.9403 - task_1_output_precision_120: 0.9403 - task_1_output_recall_120: 0.9403 - task_2_output_accuracy: 0.8114 - task_2_output_precision_121: 0.8240 - task_2_output_recall_121: 0.8005 - task_3_output_mse: 0.4890\n",
            "loss: 0.3683888018131256\n",
            "task_1_output_loss: 0.2587340176105499\n",
            "task_2_output_loss: 0.8070075511932373\n",
            "task_3_output_loss: 0.48900365829467773\n",
            "task_1_output_accuracy: 0.9402666687965393\n",
            "task_1_output_precision_120: 0.9402666687965393\n",
            "task_1_output_recall_120: 0.9402666687965393\n",
            "task_2_output_accuracy: 0.811377763748169\n",
            "task_2_output_precision_121: 0.8239707350730896\n",
            "task_2_output_recall_121: 0.8005333542823792\n",
            "task_3_output_mse: 0.48900365829467773\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 205.91353487968445\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 5ms/step - loss: 0.3577 - task_1_output_loss: 0.2341 - task_2_output_loss: 0.8520 - task_3_output_loss: 0.3969 - task_1_output_accuracy: 0.9520 - task_1_output_precision_122: 0.9520 - task_1_output_recall_122: 0.9520 - task_2_output_accuracy: 0.8160 - task_2_output_precision_123: 0.8214 - task_2_output_recall_123: 0.8103 - task_3_output_mse: 0.3969\n",
            "loss: 0.3576972782611847\n",
            "task_1_output_loss: 0.2341300994157791\n",
            "task_2_output_loss: 0.8519657850265503\n",
            "task_3_output_loss: 0.39688295125961304\n",
            "task_1_output_accuracy: 0.9520000219345093\n",
            "task_1_output_precision_122: 0.9520000219345093\n",
            "task_1_output_recall_122: 0.9520000219345093\n",
            "task_2_output_accuracy: 0.8159999847412109\n",
            "task_2_output_precision_123: 0.821409285068512\n",
            "task_2_output_recall_123: 0.8103111386299133\n",
            "task_3_output_mse: 0.39688295125961304\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 181.59022998809814\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.4208 - task_1_output_loss: 0.3050 - task_2_output_loss: 0.8841 - task_3_output_loss: 1.5189 - task_1_output_accuracy: 0.9465 - task_1_output_precision_124: 0.9465 - task_1_output_recall_124: 0.9465 - task_2_output_accuracy: 0.8114 - task_2_output_precision_125: 0.8177 - task_2_output_recall_125: 0.8028 - task_3_output_mse: 1.5189\n",
            "loss: 0.4208431541919708\n",
            "task_1_output_loss: 0.3050307631492615\n",
            "task_2_output_loss: 0.8840928077697754\n",
            "task_3_output_loss: 1.5189106464385986\n",
            "task_1_output_accuracy: 0.9464889168739319\n",
            "task_1_output_precision_124: 0.9464889168739319\n",
            "task_1_output_recall_124: 0.9464889168739319\n",
            "task_2_output_accuracy: 0.811377763748169\n",
            "task_2_output_precision_125: 0.817671537399292\n",
            "task_2_output_recall_125: 0.8028444647789001\n",
            "task_3_output_mse: 1.5189106464385986\n",
            "Starting training on batch of models for gamma values  [[0.8, 0.2, 0, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.8, 0.2, 0, 0, 0]\n",
            "Training time: 206.4255588054657\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 2s 6ms/step - loss: 0.4275 - task_1_output_loss: 0.2946 - task_2_output_loss: 0.9594 - task_3_output_loss: 0.5969 - task_1_output_accuracy: 0.9479 - task_1_output_precision_126: 0.9479 - task_1_output_recall_126: 0.9479 - task_2_output_accuracy: 0.8153 - task_2_output_precision_127: 0.8207 - task_2_output_recall_127: 0.8098 - task_3_output_mse: 0.5969\n",
            "loss: 0.42754852771759033\n",
            "task_1_output_loss: 0.29458341002464294\n",
            "task_2_output_loss: 0.9594088792800903\n",
            "task_3_output_loss: 0.5968636274337769\n",
            "task_1_output_accuracy: 0.9479110836982727\n",
            "task_1_output_precision_126: 0.9479110836982727\n",
            "task_1_output_recall_126: 0.9479110836982727\n",
            "task_2_output_accuracy: 0.8152889013290405\n",
            "task_2_output_precision_127: 0.8207207322120667\n",
            "task_2_output_recall_127: 0.8097777962684631\n",
            "task_3_output_mse: 0.5968636274337769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REDES RECORRENTES ...\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8DtG_FUWV6Qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.reshape(x_train, (x_train.shape[0], 1250, 1, 1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], 1250, 1, 1))"
      ],
      "metadata": {
        "id": "7U-_WSoxbgRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA4BMEc3dBmB",
        "outputId": "1fc8a84e-c62f-4b55-f35d-0e6e6a265d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24588, 1250)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tkJlOjDxXWk",
        "outputId": "58050684-ed04-4c9d-a6a4-661550bc517b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5625, 1250, 1, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape = (24588, 1250, 1)\n",
        "x_test.shape = (x_test.shape[0], 1250, 1)\n",
        "x_train = np.repeat(x_train[..., np.newaxis], 3, -1)\n",
        "x_test = np.repeat(x_test[..., np.newaxis], 3, -1)"
      ],
      "metadata": {
        "id": "-tpyJM3YznHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying to improve multitask!!!\n",
        "\n",
        "#best result --> no augmentation\n",
        "\n",
        "\"\"\" Functions for creating, compiling and training model\"\"\"\n",
        "\n",
        "# Architecture:\n",
        "# Main branch\n",
        "# Branch1 => Decides wheter life threatening (VF or VT style) or not (SR and others)\n",
        "# Branch2 => Classify the input\n",
        "\n",
        "\n",
        "# labels,Rhythm\n",
        "# AFb,Atrial Fibrillation\n",
        "# AFt,Atrial Flutter\n",
        "# SR,Sinus Rhythm\n",
        "# SVT,Supraventricular Tachycardia\n",
        "# VFb,Ventricular Fibrillation\n",
        "# VFt,Ventricular Flutter\n",
        "# VPD,Ventricular Premature Depolarizations\n",
        "# VT,Ventricular Tachycardia\n",
        "\n",
        "\n",
        "def gen_model():\n",
        "    inputs = keras.layers.Input(shape=(1250, 1, 3), name='input')\n",
        "    effNet = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", input_tensor=inputs, include_top=False)\n",
        "    main_branch = keras.layers.Flatten()(effNet.output)\n",
        "    main_branch = keras.layers.Reshape((40, 1280))(main_branch)\n",
        "    main_branch = keras.layers.LSTM(units=10, return_sequences=True) (main_branch)\n",
        "    main_branch = keras.layers.LSTM(units=10, return_sequences=True) (main_branch)\n",
        "    main_branch = keras.layers.LSTM(units=10) (main_branch)\n",
        "    main_branch = keras.layers.Dropout(0.2) (main_branch)\n",
        "\n",
        "\n",
        "    #main_branch = keras.layers.Conv1D(filters=3, kernel_size=6, strides=2, activation=\"relu\") (inputs)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=5, kernel_size=5, strides=2,  activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=10, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=20, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=20, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=32, kernel_size=1, strides=32, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Flatten() (main_branch)\n",
        "    #main_branch = keras.layers.Dropout(0.5) (main_branch)\n",
        "    #main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.Dropout(0.1) (main_branch)\n",
        "    #main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.Dropout(0.1) (main_branch)\n",
        "    #main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "\n",
        "    #branch1 = keras.layers.Dense(128, activation=\"relu\") (branch1)\n",
        "    #branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    #branch1 = keras.layers.Dense(128, activation=\"relu\") (branch1)\n",
        "    #branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    #branch1 = keras.layers.Dropout(0.2) (branch1)\n",
        "\n",
        "    # Decides wheter life threatening (VF or VT style) or not (SR and others)\n",
        "    branch1 = keras.layers.Dense(2, activation=\"softmax\", name='task_1_output') (main_branch)\n",
        "\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (main_branch)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (branch2)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (branch2)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dropout(0.2) (branch2)\n",
        "\n",
        "    # Classify the input\n",
        "    branch2 = keras.layers.Dense(8, activation=\"softmax\", name='task_2_output') (main_branch)\n",
        "\n",
        "    # mean\n",
        "    branch3 = keras.layers.Dense(1, activation=\"relu\", name='task_3_output') (main_branch)\n",
        "\n",
        "    ## std\n",
        "    #branch4 = keras.layers.Dense(1, activation=\"relu\", name='task_4_output') (main_branch)\n",
        "#\n",
        "    ## var\n",
        "    #branch5 = keras.layers.Dense(1, activation=\"relu\", name='task_5_output') (main_branch)\n",
        "\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = [branch1, branch2, branch3,]) #branch4, branch5])\n",
        "\n",
        "    return model\n",
        "\n",
        "# loss_weight -> [0, 1]\n",
        "# the weight for the second task is calculated by '1 - loss_weight'\n",
        "def compile_model(model, loss_weight1, loss_weight2, loss_weight3, loss_weight4, loss_weight5):\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0002),\n",
        "                  loss={'task_1_output': 'binary_crossentropy',\n",
        "                        'task_2_output': 'categorical_crossentropy',\n",
        "                        'task_3_output': 'mse',\n",
        "                        #'task_4_output': 'mse',\n",
        "                        #'task_5_output': 'mse'\n",
        "                        },\n",
        "                  loss_weights={'task_1_output': loss_weight1,\n",
        "                                'task_2_output': loss_weight2,\n",
        "                                'task_3_output': loss_weight3,\n",
        "                                #'task_4_output': loss_weight4,\n",
        "                                #'task_5_output': loss_weight5\n",
        "                                },\n",
        "                  metrics={'task_1_output' : [\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
        "                           'task_2_output' : [\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
        "                           'task_3_output' : \"mse\",\n",
        "                           #'task_4_output' : \"mse\",\n",
        "                           #'task_5_output' : \"mse\"\n",
        "                           })\n",
        "    return model\n",
        "\n",
        "def fit_batch(gamma_values, epochs=30, batch_size=32, save_models=False, models_dir=\"./trained_models\", verbose=0):\n",
        "\n",
        "    history = list()\n",
        "    trained_models = list()\n",
        "    test_scores = list()\n",
        "\n",
        "    start_epoch = 10\n",
        "    swa = SWA(start_epoch=start_epoch,\n",
        "          lr_schedule='cyclic',\n",
        "          swa_lr=0.0001,\n",
        "          swa_lr2=0.0005,\n",
        "          swa_freq=5,\n",
        "          batch_size=batch_size,\n",
        "          verbose=1)\n",
        "\n",
        "    if save_models and not os.path.isdir(models_dir):\n",
        "      os.mkdir(models_dir)\n",
        "\n",
        "    print('Starting training on batch of models for gamma values ', gamma_values, '\\n\\n')\n",
        "\n",
        "    for i, gamma in enumerate(gamma_values):\n",
        "\n",
        "        print('Training model for gamma equal to ', gamma)\n",
        "        model = gen_model()\n",
        "        model = compile_model(model, gamma[0], gamma[1], gamma[2], gamma[3], gamma[4])\n",
        "        start = time.time()\n",
        "        model_history = model.fit({'input': x_train},\n",
        "                            {'task_1_output': y_train_1, 'task_2_output': y_train_2, 'task_3_output': y_train_3,\n",
        "                             #'task_4_output': y_train_4, 'task_5_output': y_train_5\n",
        "                             },\n",
        "                            epochs=epochs, batch_size=batch_size, verbose=verbose) # callbacks=[swa],\n",
        "        print(f'Training time: {time.time() - start}\\n')\n",
        "        history.append(model_history)\n",
        "        trained_models.append(model)\n",
        "        if save_models:\n",
        "          model.save(os.path.join(models_dir, f\"{i}th-model\"))\n",
        "\n",
        "        test_score = model.evaluate({'input': x_test}, {'task_1_output': y_test_1, 'task_2_output': y_test_2, 'task_3_output': y_test_3,\n",
        "                                                        #'task_4_output': y_test_4, 'task_5_output': y_test_5\n",
        "                                                        })\n",
        "        for metric, result in zip(model.metrics_names, test_score):\n",
        "          print(f\"{metric}: {result}\")\n",
        "\n",
        "        test_scores.append(test_score)\n",
        "\n",
        "    return history, trained_models, test_scores\n",
        "\n",
        "def plot_multitask_accuracies(gammas, training_history):\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for history in training_history:\n",
        "\n",
        "        print(f'\\nPlotting Accuracy/Precision/Recall vs Epochs for value of gamma number {gammas[counter]}\\n')\n",
        "        plt.plot(range(len(history.history['task_1_output_accuracy'])), history.history['task_1_output_accuracy'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_accuracy'])), history.history['task_2_output_accuracy'], c='b', label='Task 2')\n",
        "        plt.plot(range(len(history.history['task_1_output_precision'])), history.history['task_1_output_precision'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_precision'])), history.history['task_2_output_precision'], c='b', label='Task 2')\n",
        "        plt.plot(range(len(history.history['task_1_output_recall'])), history.history['task_1_output_recall'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_recall'])), history.history['task_2_output_recall'], c='b', label='Task 2')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        counter += 1\n",
        "\n",
        "\"\"\"Actually training the model\"\"\"\n",
        "#gamma_values = [ [0.2, 0.2, 0.2, 0.2, 0.2],\n",
        "#                [0.8, 0.1, 0.0333, 0.0333, 0.0333],\n",
        "#                [0.5, 0.125, 0.125, 0.125, 0.125],\n",
        "#                [0.5, 0.2, 0.1, 0.1, 0.1],\n",
        "#                [0.6, 0.3, 0.033, 0.033, 0.033]]\n",
        "\n",
        "gamma_values = [  #[0.5, 0.25, 0.25, 0, 0],\n",
        "                  #[0.6, 0.2, 0.2, 0, 0],\n",
        "                  [0.7, 0.2, 0.1, 0, 0],\n",
        "                  #[0.8, 0.1, 0.1, 0, 0],\n",
        "                  ]\n",
        "\n",
        "history, trained_models, _ = fit_batch(gamma_values, epochs=50, save_models=True, models_dir=\"./trained_models_sixth_augmentation\", verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hsd1MCd2V5kp",
        "outputId": "1a51882e-f791-4f00-e470-d9fd35d1ef9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training on batch of models for gamma values  [[0.7, 0.2, 0.1, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.7, 0.2, 0.1, 0, 0]\n",
            "Epoch 1/50\n",
            "769/769 [==============================] - 124s 78ms/step - loss: 0.4667 - task_1_output_loss: 0.2881 - task_2_output_loss: 1.3107 - task_3_output_loss: 0.0290 - task_1_output_accuracy: 0.9522 - task_1_output_precision_2: 0.9522 - task_1_output_recall_2: 0.9522 - task_2_output_accuracy: 0.6701 - task_2_output_precision_3: 0.8614 - task_2_output_recall_3: 0.2370 - task_3_output_mse: 0.0290\n",
            "Epoch 2/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.2185 - task_1_output_loss: 0.1018 - task_2_output_loss: 0.7301 - task_3_output_loss: 0.0121 - task_1_output_accuracy: 0.9836 - task_1_output_precision_2: 0.9836 - task_1_output_recall_2: 0.9836 - task_2_output_accuracy: 0.8457 - task_2_output_precision_3: 0.8629 - task_2_output_recall_3: 0.7632 - task_3_output_mse: 0.0121\n",
            "Epoch 3/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.1720 - task_1_output_loss: 0.0633 - task_2_output_loss: 0.6370 - task_3_output_loss: 0.0034 - task_1_output_accuracy: 0.9882 - task_1_output_precision_2: 0.9882 - task_1_output_recall_2: 0.9882 - task_2_output_accuracy: 0.8545 - task_2_output_precision_3: 0.8673 - task_2_output_recall_3: 0.8132 - task_3_output_mse: 0.0034\n",
            "Epoch 4/50\n",
            "769/769 [==============================] - 57s 74ms/step - loss: 0.1518 - task_1_output_loss: 0.0462 - task_2_output_loss: 0.5970 - task_3_output_loss: 0.0010 - task_1_output_accuracy: 0.9910 - task_1_output_precision_2: 0.9910 - task_1_output_recall_2: 0.9910 - task_2_output_accuracy: 0.8575 - task_2_output_precision_3: 0.8690 - task_2_output_recall_3: 0.8336 - task_3_output_mse: 0.0010\n",
            "Epoch 5/50\n",
            "769/769 [==============================] - 56s 73ms/step - loss: 0.1311 - task_1_output_loss: 0.0314 - task_2_output_loss: 0.5456 - task_3_output_loss: 3.4186e-04 - task_1_output_accuracy: 0.9943 - task_1_output_precision_2: 0.9943 - task_1_output_recall_2: 0.9943 - task_2_output_accuracy: 0.8625 - task_2_output_precision_3: 0.8716 - task_2_output_recall_3: 0.8473 - task_3_output_mse: 3.4186e-04\n",
            "Epoch 6/50\n",
            "769/769 [==============================] - 57s 74ms/step - loss: 0.1102 - task_1_output_loss: 0.0237 - task_2_output_loss: 0.4680 - task_3_output_loss: 1.3715e-04 - task_1_output_accuracy: 0.9966 - task_1_output_precision_2: 0.9966 - task_1_output_recall_2: 0.9966 - task_2_output_accuracy: 0.8657 - task_2_output_precision_3: 0.8786 - task_2_output_recall_3: 0.8554 - task_3_output_mse: 1.3715e-04\n",
            "Epoch 7/50\n",
            "769/769 [==============================] - 57s 73ms/step - loss: 0.0999 - task_1_output_loss: 0.0281 - task_2_output_loss: 0.4013 - task_3_output_loss: 6.2032e-05 - task_1_output_accuracy: 0.9952 - task_1_output_precision_2: 0.9952 - task_1_output_recall_2: 0.9952 - task_2_output_accuracy: 0.8699 - task_2_output_precision_3: 0.9066 - task_2_output_recall_3: 0.8528 - task_3_output_mse: 6.2032e-05\n",
            "Epoch 8/50\n",
            "769/769 [==============================] - 56s 73ms/step - loss: 0.0866 - task_1_output_loss: 0.0241 - task_2_output_loss: 0.3488 - task_3_output_loss: 2.4511e-05 - task_1_output_accuracy: 0.9953 - task_1_output_precision_2: 0.9953 - task_1_output_recall_2: 0.9953 - task_2_output_accuracy: 0.8863 - task_2_output_precision_3: 0.9364 - task_2_output_recall_3: 0.8596 - task_3_output_mse: 2.4511e-05\n",
            "Epoch 9/50\n",
            "769/769 [==============================] - 57s 74ms/step - loss: 0.0755 - task_1_output_loss: 0.0191 - task_2_output_loss: 0.3104 - task_3_output_loss: 1.3972e-05 - task_1_output_accuracy: 0.9962 - task_1_output_precision_2: 0.9962 - task_1_output_recall_2: 0.9962 - task_2_output_accuracy: 0.9028 - task_2_output_precision_3: 0.9502 - task_2_output_recall_3: 0.8714 - task_3_output_mse: 1.3972e-05\n",
            "Epoch 10/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0570 - task_1_output_loss: 0.0087 - task_2_output_loss: 0.2545 - task_3_output_loss: 7.4997e-06 - task_1_output_accuracy: 0.9991 - task_1_output_precision_2: 0.9991 - task_1_output_recall_2: 0.9991 - task_2_output_accuracy: 0.9197 - task_2_output_precision_3: 0.9627 - task_2_output_recall_3: 0.8881 - task_3_output_mse: 7.4997e-06\n",
            "Epoch 11/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0591 - task_1_output_loss: 0.0143 - task_2_output_loss: 0.2452 - task_3_output_loss: 5.1958e-06 - task_1_output_accuracy: 0.9972 - task_1_output_precision_2: 0.9972 - task_1_output_recall_2: 0.9972 - task_2_output_accuracy: 0.9215 - task_2_output_precision_3: 0.9632 - task_2_output_recall_3: 0.8894 - task_3_output_mse: 5.1958e-06\n",
            "Epoch 12/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0513 - task_1_output_loss: 0.0091 - task_2_output_loss: 0.2247 - task_3_output_loss: 3.1425e-06 - task_1_output_accuracy: 0.9983 - task_1_output_precision_2: 0.9983 - task_1_output_recall_2: 0.9983 - task_2_output_accuracy: 0.9257 - task_2_output_precision_3: 0.9677 - task_2_output_recall_3: 0.8930 - task_3_output_mse: 3.1425e-06\n",
            "Epoch 13/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0516 - task_1_output_loss: 0.0118 - task_2_output_loss: 0.2165 - task_3_output_loss: 3.0907e-06 - task_1_output_accuracy: 0.9972 - task_1_output_precision_2: 0.9972 - task_1_output_recall_2: 0.9972 - task_2_output_accuracy: 0.9258 - task_2_output_precision_3: 0.9677 - task_2_output_recall_3: 0.8930 - task_3_output_mse: 3.0907e-06\n",
            "Epoch 14/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0487 - task_1_output_loss: 0.0130 - task_2_output_loss: 0.1979 - task_3_output_loss: 2.3631e-06 - task_1_output_accuracy: 0.9978 - task_1_output_precision_2: 0.9978 - task_1_output_recall_2: 0.9978 - task_2_output_accuracy: 0.9285 - task_2_output_precision_3: 0.9698 - task_2_output_recall_3: 0.8986 - task_3_output_mse: 2.3631e-06\n",
            "Epoch 15/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0424 - task_1_output_loss: 0.0081 - task_2_output_loss: 0.1835 - task_3_output_loss: 1.9497e-06 - task_1_output_accuracy: 0.9986 - task_1_output_precision_2: 0.9986 - task_1_output_recall_2: 0.9986 - task_2_output_accuracy: 0.9302 - task_2_output_precision_3: 0.9699 - task_2_output_recall_3: 0.9029 - task_3_output_mse: 1.9497e-06\n",
            "Epoch 16/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0363 - task_1_output_loss: 0.0061 - task_2_output_loss: 0.1602 - task_3_output_loss: 1.9484e-06 - task_1_output_accuracy: 0.9991 - task_1_output_precision_2: 0.9991 - task_1_output_recall_2: 0.9991 - task_2_output_accuracy: 0.9368 - task_2_output_precision_3: 0.9720 - task_2_output_recall_3: 0.9109 - task_3_output_mse: 1.9484e-06\n",
            "Epoch 17/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0386 - task_1_output_loss: 0.0084 - task_2_output_loss: 0.1635 - task_3_output_loss: 1.9988e-06 - task_1_output_accuracy: 0.9984 - task_1_output_precision_2: 0.9984 - task_1_output_recall_2: 0.9984 - task_2_output_accuracy: 0.9375 - task_2_output_precision_3: 0.9758 - task_2_output_recall_3: 0.9075 - task_3_output_mse: 1.9988e-06\n",
            "Epoch 18/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0343 - task_1_output_loss: 0.0053 - task_2_output_loss: 0.1528 - task_3_output_loss: 2.0242e-06 - task_1_output_accuracy: 0.9990 - task_1_output_precision_2: 0.9990 - task_1_output_recall_2: 0.9990 - task_2_output_accuracy: 0.9370 - task_2_output_precision_3: 0.9731 - task_2_output_recall_3: 0.9139 - task_3_output_mse: 2.0242e-06\n",
            "Epoch 19/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0337 - task_1_output_loss: 0.0080 - task_2_output_loss: 0.1404 - task_3_output_loss: 1.8657e-06 - task_1_output_accuracy: 0.9985 - task_1_output_precision_2: 0.9985 - task_1_output_recall_2: 0.9985 - task_2_output_accuracy: 0.9423 - task_2_output_precision_3: 0.9781 - task_2_output_recall_3: 0.9184 - task_3_output_mse: 1.8657e-06\n",
            "Epoch 20/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0317 - task_1_output_loss: 0.0066 - task_2_output_loss: 0.1353 - task_3_output_loss: 1.8060e-06 - task_1_output_accuracy: 0.9987 - task_1_output_precision_2: 0.9987 - task_1_output_recall_2: 0.9987 - task_2_output_accuracy: 0.9418 - task_2_output_precision_3: 0.9770 - task_2_output_recall_3: 0.9240 - task_3_output_mse: 1.8060e-06\n",
            "Epoch 21/50\n",
            "769/769 [==============================] - 60s 78ms/step - loss: 0.0268 - task_1_output_loss: 0.0043 - task_2_output_loss: 0.1188 - task_3_output_loss: 1.8023e-06 - task_1_output_accuracy: 0.9991 - task_1_output_precision_2: 0.9991 - task_1_output_recall_2: 0.9991 - task_2_output_accuracy: 0.9481 - task_2_output_precision_3: 0.9798 - task_2_output_recall_3: 0.9272 - task_3_output_mse: 1.8023e-06\n",
            "Epoch 22/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0286 - task_1_output_loss: 0.0058 - task_2_output_loss: 0.1229 - task_3_output_loss: 1.7985e-06 - task_1_output_accuracy: 0.9989 - task_1_output_precision_2: 0.9989 - task_1_output_recall_2: 0.9989 - task_2_output_accuracy: 0.9477 - task_2_output_precision_3: 0.9777 - task_2_output_recall_3: 0.9263 - task_3_output_mse: 1.7985e-06\n",
            "Epoch 23/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0307 - task_1_output_loss: 0.0079 - task_2_output_loss: 0.1258 - task_3_output_loss: 1.8014e-06 - task_1_output_accuracy: 0.9984 - task_1_output_precision_2: 0.9984 - task_1_output_recall_2: 0.9984 - task_2_output_accuracy: 0.9488 - task_2_output_precision_3: 0.9768 - task_2_output_recall_3: 0.9264 - task_3_output_mse: 1.8014e-06\n",
            "Epoch 24/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0267 - task_1_output_loss: 0.0044 - task_2_output_loss: 0.1182 - task_3_output_loss: 1.8027e-06 - task_1_output_accuracy: 0.9992 - task_1_output_precision_2: 0.9992 - task_1_output_recall_2: 0.9992 - task_2_output_accuracy: 0.9508 - task_2_output_precision_3: 0.9760 - task_2_output_recall_3: 0.9289 - task_3_output_mse: 1.8027e-06\n",
            "Epoch 25/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0253 - task_1_output_loss: 0.0038 - task_2_output_loss: 0.1134 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9992 - task_1_output_precision_2: 0.9992 - task_1_output_recall_2: 0.9992 - task_2_output_accuracy: 0.9516 - task_2_output_precision_3: 0.9726 - task_2_output_recall_3: 0.9342 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 26/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0239 - task_1_output_loss: 0.0043 - task_2_output_loss: 0.1047 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9991 - task_1_output_precision_2: 0.9991 - task_1_output_recall_2: 0.9991 - task_2_output_accuracy: 0.9567 - task_2_output_precision_3: 0.9792 - task_2_output_recall_3: 0.9346 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 27/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0207 - task_1_output_loss: 0.0019 - task_2_output_loss: 0.0968 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9998 - task_1_output_precision_2: 0.9998 - task_1_output_recall_2: 0.9998 - task_2_output_accuracy: 0.9571 - task_2_output_precision_3: 0.9781 - task_2_output_recall_3: 0.9388 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 28/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0210 - task_1_output_loss: 0.0032 - task_2_output_loss: 0.0941 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9997 - task_1_output_precision_2: 0.9997 - task_1_output_recall_2: 0.9997 - task_2_output_accuracy: 0.9595 - task_2_output_precision_3: 0.9770 - task_2_output_recall_3: 0.9439 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 29/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0216 - task_1_output_loss: 0.0026 - task_2_output_loss: 0.0988 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9996 - task_1_output_precision_2: 0.9996 - task_1_output_recall_2: 0.9996 - task_2_output_accuracy: 0.9591 - task_2_output_precision_3: 0.9779 - task_2_output_recall_3: 0.9416 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 30/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0237 - task_1_output_loss: 0.0062 - task_2_output_loss: 0.0968 - task_3_output_loss: 1.7992e-06 - task_1_output_accuracy: 0.9987 - task_1_output_precision_2: 0.9987 - task_1_output_recall_2: 0.9987 - task_2_output_accuracy: 0.9593 - task_2_output_precision_3: 0.9787 - task_2_output_recall_3: 0.9409 - task_3_output_mse: 1.7992e-06\n",
            "Epoch 31/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0187 - task_1_output_loss: 0.0021 - task_2_output_loss: 0.0860 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9996 - task_1_output_precision_2: 0.9996 - task_1_output_recall_2: 0.9996 - task_2_output_accuracy: 0.9630 - task_2_output_precision_3: 0.9778 - task_2_output_recall_3: 0.9485 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 32/50\n",
            "769/769 [==============================] - 57s 74ms/step - loss: 0.0188 - task_1_output_loss: 0.0033 - task_2_output_loss: 0.0824 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9995 - task_1_output_precision_2: 0.9995 - task_1_output_recall_2: 0.9995 - task_2_output_accuracy: 0.9631 - task_2_output_precision_3: 0.9803 - task_2_output_recall_3: 0.9467 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 33/50\n",
            "769/769 [==============================] - 57s 74ms/step - loss: 0.0275 - task_1_output_loss: 0.0094 - task_2_output_loss: 0.1047 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9981 - task_1_output_precision_2: 0.9981 - task_1_output_recall_2: 0.9981 - task_2_output_accuracy: 0.9574 - task_2_output_precision_3: 0.9755 - task_2_output_recall_3: 0.9404 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 34/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0200 - task_1_output_loss: 0.0040 - task_2_output_loss: 0.0861 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9991 - task_1_output_precision_2: 0.9991 - task_1_output_recall_2: 0.9991 - task_2_output_accuracy: 0.9614 - task_2_output_precision_3: 0.9773 - task_2_output_recall_3: 0.9456 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 35/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0158 - task_1_output_loss: 0.0014 - task_2_output_loss: 0.0742 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9998 - task_1_output_precision_2: 0.9998 - task_1_output_recall_2: 0.9998 - task_2_output_accuracy: 0.9653 - task_2_output_precision_3: 0.9788 - task_2_output_recall_3: 0.9511 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 36/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0154 - task_1_output_loss: 0.0013 - task_2_output_loss: 0.0724 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9998 - task_1_output_precision_2: 0.9998 - task_1_output_recall_2: 0.9998 - task_2_output_accuracy: 0.9651 - task_2_output_precision_3: 0.9808 - task_2_output_recall_3: 0.9492 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 37/50\n",
            "769/769 [==============================] - 60s 78ms/step - loss: 0.0276 - task_1_output_loss: 0.0087 - task_2_output_loss: 0.1077 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9981 - task_1_output_precision_2: 0.9981 - task_1_output_recall_2: 0.9981 - task_2_output_accuracy: 0.9567 - task_2_output_precision_3: 0.9743 - task_2_output_recall_3: 0.9414 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 38/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0213 - task_1_output_loss: 0.0048 - task_2_output_loss: 0.0894 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9989 - task_1_output_precision_2: 0.9989 - task_1_output_recall_2: 0.9989 - task_2_output_accuracy: 0.9616 - task_2_output_precision_3: 0.9764 - task_2_output_recall_3: 0.9453 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 39/50\n",
            "769/769 [==============================] - 60s 78ms/step - loss: 0.0172 - task_1_output_loss: 0.0026 - task_2_output_loss: 0.0768 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9994 - task_1_output_precision_2: 0.9994 - task_1_output_recall_2: 0.9994 - task_2_output_accuracy: 0.9641 - task_2_output_precision_3: 0.9790 - task_2_output_recall_3: 0.9490 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 40/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0178 - task_1_output_loss: 0.0030 - task_2_output_loss: 0.0782 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9993 - task_1_output_precision_2: 0.9993 - task_1_output_recall_2: 0.9993 - task_2_output_accuracy: 0.9662 - task_2_output_precision_3: 0.9800 - task_2_output_recall_3: 0.9502 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 41/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0141 - task_1_output_loss: 0.0010 - task_2_output_loss: 0.0670 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9999 - task_1_output_precision_2: 0.9999 - task_1_output_recall_2: 0.9999 - task_2_output_accuracy: 0.9665 - task_2_output_precision_3: 0.9797 - task_2_output_recall_3: 0.9525 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 42/50\n",
            "769/769 [==============================] - 60s 78ms/step - loss: 0.0170 - task_1_output_loss: 0.0024 - task_2_output_loss: 0.0767 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9996 - task_1_output_precision_2: 0.9996 - task_1_output_recall_2: 0.9996 - task_2_output_accuracy: 0.9629 - task_2_output_precision_3: 0.9769 - task_2_output_recall_3: 0.9503 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 43/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0176 - task_1_output_loss: 0.0026 - task_2_output_loss: 0.0788 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9997 - task_1_output_precision_2: 0.9997 - task_1_output_recall_2: 0.9997 - task_2_output_accuracy: 0.9641 - task_2_output_precision_3: 0.9786 - task_2_output_recall_3: 0.9488 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 44/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0180 - task_1_output_loss: 0.0038 - task_2_output_loss: 0.0766 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9993 - task_1_output_precision_2: 0.9993 - task_1_output_recall_2: 0.9993 - task_2_output_accuracy: 0.9649 - task_2_output_precision_3: 0.9775 - task_2_output_recall_3: 0.9512 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 45/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0172 - task_1_output_loss: 0.0027 - task_2_output_loss: 0.0764 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9993 - task_1_output_precision_2: 0.9993 - task_1_output_recall_2: 0.9993 - task_2_output_accuracy: 0.9656 - task_2_output_precision_3: 0.9774 - task_2_output_recall_3: 0.9517 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 46/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0152 - task_1_output_loss: 0.0016 - task_2_output_loss: 0.0701 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9997 - task_1_output_precision_2: 0.9997 - task_1_output_recall_2: 0.9997 - task_2_output_accuracy: 0.9643 - task_2_output_precision_3: 0.9775 - task_2_output_recall_3: 0.9520 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 47/50\n",
            "769/769 [==============================] - 60s 77ms/step - loss: 0.0162 - task_1_output_loss: 0.0023 - task_2_output_loss: 0.0731 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9995 - task_1_output_precision_2: 0.9995 - task_1_output_recall_2: 0.9995 - task_2_output_accuracy: 0.9631 - task_2_output_precision_3: 0.9768 - task_2_output_recall_3: 0.9503 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 48/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0164 - task_1_output_loss: 0.0034 - task_2_output_loss: 0.0700 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9995 - task_1_output_precision_2: 0.9995 - task_1_output_recall_2: 0.9995 - task_2_output_accuracy: 0.9663 - task_2_output_precision_3: 0.9781 - task_2_output_recall_3: 0.9535 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 49/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0158 - task_1_output_loss: 0.0025 - task_2_output_loss: 0.0704 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9996 - task_1_output_precision_2: 0.9996 - task_1_output_recall_2: 0.9996 - task_2_output_accuracy: 0.9666 - task_2_output_precision_3: 0.9804 - task_2_output_recall_3: 0.9522 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 50/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0134 - task_1_output_loss: 7.6253e-04 - task_2_output_loss: 0.0643 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 1.0000 - task_1_output_precision_2: 1.0000 - task_1_output_recall_2: 1.0000 - task_2_output_accuracy: 0.9687 - task_2_output_precision_3: 0.9787 - task_2_output_recall_3: 0.9559 - task_3_output_mse: 1.7973e-06\n",
            "Training time: 2984.1307826042175\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 87). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-95161963e3a5>\u001b[0m in \u001b[0;36m<cell line: 191>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    189\u001b[0m                   ]\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./trained_models_sixth_augmentation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-95161963e3a5>\u001b[0m in \u001b[0;36mfit_batch\u001b[0;34m(gamma_values, epochs, batch_size, save_models, models_dir, verbose)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mtrained_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{i}th-model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         test_score = model.evaluate({'input': x_test}, {'task_1_output': y_test_1, 'task_2_output': y_test_2, 'task_3_output': y_test_3,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying to improve multitask!!!\n",
        "\n",
        "#best result --> no augmentation\n",
        "\n",
        "\"\"\" Functions for creating, compiling and training model\"\"\"\n",
        "\n",
        "# Architecture:\n",
        "# Main branch\n",
        "# Branch1 => Decides wheter life threatening (VF or VT style) or not (SR and others)\n",
        "# Branch2 => Classify the input\n",
        "\n",
        "\n",
        "# labels,Rhythm\n",
        "# AFb,Atrial Fibrillation\n",
        "# AFt,Atrial Flutter\n",
        "# SR,Sinus Rhythm\n",
        "# SVT,Supraventricular Tachycardia\n",
        "# VFb,Ventricular Fibrillation\n",
        "# VFt,Ventricular Flutter\n",
        "# VPD,Ventricular Premature Depolarizations\n",
        "# VT,Ventricular Tachycardia\n",
        "\n",
        "\n",
        "def gen_model():\n",
        "    inputs = keras.layers.Input(shape=(1250, 1, 3), name='input')\n",
        "    effNet = tf.keras.applications.EfficientNetB0(weights=\"imagenet\", input_tensor=inputs, include_top=False)\n",
        "    main_branch = keras.layers.Flatten()(effNet.output)\n",
        "    main_branch = keras.layers.Reshape((40, 1280))(main_branch)\n",
        "    main_branch = keras.layers.LSTM(units=10, return_sequences=True) (main_branch)\n",
        "    main_branch = keras.layers.LSTM(units=10, return_sequences=True) (main_branch)\n",
        "    main_branch = keras.layers.LSTM(units=10) (main_branch)\n",
        "    main_branch = keras.layers.Dropout(0.2) (main_branch)\n",
        "\n",
        "\n",
        "    #main_branch = keras.layers.Conv1D(filters=3, kernel_size=6, strides=2, activation=\"relu\") (inputs)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=5, kernel_size=5, strides=2,  activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=10, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=20, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=20, kernel_size=4, strides=2,  activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Conv1D(filters=32, kernel_size=1, strides=32, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    #main_branch = keras.layers.Flatten() (main_branch)\n",
        "    #main_branch = keras.layers.Dropout(0.5) (main_branch)\n",
        "    #main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.Dropout(0.1) (main_branch)\n",
        "    #main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.Dropout(0.1) (main_branch)\n",
        "    #main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    #main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "\n",
        "    #branch1 = keras.layers.Dense(128, activation=\"relu\") (branch1)\n",
        "    #branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    #branch1 = keras.layers.Dense(128, activation=\"relu\") (branch1)\n",
        "    #branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    #branch1 = keras.layers.Dropout(0.2) (branch1)\n",
        "\n",
        "    # Decides wheter life threatening (VF or VT style) or not (SR and others)\n",
        "    branch1 = keras.layers.Dense(2, activation=\"softmax\", name='task_1_output') (main_branch)\n",
        "\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (main_branch)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (branch2)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dense(128, activation=\"relu\") (branch2)\n",
        "    #branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    #branch2 = keras.layers.Dropout(0.2) (branch2)\n",
        "\n",
        "    # Classify the input\n",
        "    branch2 = keras.layers.Dense(8, activation=\"softmax\", name='task_2_output') (main_branch)\n",
        "\n",
        "    # mean\n",
        "    branch3 = keras.layers.Dense(1, activation=\"relu\", name='task_3_output') (main_branch)\n",
        "\n",
        "    ## std\n",
        "    #branch4 = keras.layers.Dense(1, activation=\"relu\", name='task_4_output') (main_branch)\n",
        "#\n",
        "    ## var\n",
        "    #branch5 = keras.layers.Dense(1, activation=\"relu\", name='task_5_output') (main_branch)\n",
        "\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = [branch1, branch2, branch3,]) #branch4, branch5])\n",
        "\n",
        "    return model\n",
        "\n",
        "# loss_weight -> [0, 1]\n",
        "# the weight for the second task is calculated by '1 - loss_weight'\n",
        "def compile_model(model, loss_weight1, loss_weight2, loss_weight3, loss_weight4, loss_weight5):\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0002),\n",
        "                  loss={'task_1_output': 'binary_crossentropy',\n",
        "                        'task_2_output': 'categorical_crossentropy',\n",
        "                        'task_3_output': 'mse',\n",
        "                        #'task_4_output': 'mse',\n",
        "                        #'task_5_output': 'mse'\n",
        "                        },\n",
        "                  loss_weights={'task_1_output': loss_weight1,\n",
        "                                'task_2_output': loss_weight2,\n",
        "                                'task_3_output': loss_weight3,\n",
        "                                #'task_4_output': loss_weight4,\n",
        "                                #'task_5_output': loss_weight5\n",
        "                                },\n",
        "                  metrics={'task_1_output' : [\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
        "                           'task_2_output' : [\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
        "                           'task_3_output' : \"mse\",\n",
        "                           #'task_4_output' : \"mse\",\n",
        "                           #'task_5_output' : \"mse\"\n",
        "                           })\n",
        "    return model\n",
        "\n",
        "def fit_batch(gamma_values, epochs=30, batch_size=32, save_models=False, models_dir=\"./trained_models\", verbose=0):\n",
        "\n",
        "    history = list()\n",
        "    trained_models = list()\n",
        "    test_scores = list()\n",
        "\n",
        "    start_epoch = 10\n",
        "    swa = SWA(start_epoch=start_epoch,\n",
        "          lr_schedule='cyclic',\n",
        "          swa_lr=0.0001,\n",
        "          swa_lr2=0.0005,\n",
        "          swa_freq=5,\n",
        "          batch_size=batch_size,\n",
        "          verbose=1)\n",
        "\n",
        "    if save_models and not os.path.isdir(models_dir):\n",
        "      os.mkdir(models_dir)\n",
        "\n",
        "    print('Starting training on batch of models for gamma values ', gamma_values, '\\n\\n')\n",
        "\n",
        "    for i, gamma in enumerate(gamma_values):\n",
        "\n",
        "        print('Training model for gamma equal to ', gamma)\n",
        "        model = gen_model()\n",
        "        model = compile_model(model, gamma[0], gamma[1], gamma[2], gamma[3], gamma[4])\n",
        "        start = time.time()\n",
        "        model_history = model.fit({'input': x_train},\n",
        "                            {'task_1_output': y_train_1, 'task_2_output': y_train_2, 'task_3_output': y_train_3,\n",
        "                             #'task_4_output': y_train_4, 'task_5_output': y_train_5\n",
        "                             },\n",
        "                            epochs=epochs, batch_size=batch_size, verbose=verbose) # callbacks=[swa],\n",
        "        print(f'Training time: {time.time() - start}\\n')\n",
        "        history.append(model_history)\n",
        "        trained_models.append(model)\n",
        "        #if save_models:\n",
        "        #  model.save(os.path.join(models_dir, f\"{i}th-model\"))\n",
        "\n",
        "        test_score = model.evaluate({'input': x_test}, {'task_1_output': y_test_1, 'task_2_output': y_test_2, 'task_3_output': y_test_3,\n",
        "                                                        #'task_4_output': y_test_4, 'task_5_output': y_test_5\n",
        "                                                        })\n",
        "        for metric, result in zip(model.metrics_names, test_score):\n",
        "          print(f\"{metric}: {result}\")\n",
        "\n",
        "        test_scores.append(test_score)\n",
        "\n",
        "    return history, trained_models, test_scores\n",
        "\n",
        "def plot_multitask_accuracies(gammas, training_history):\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for history in training_history:\n",
        "\n",
        "        print(f'\\nPlotting Accuracy/Precision/Recall vs Epochs for value of gamma number {gammas[counter]}\\n')\n",
        "        plt.plot(range(len(history.history['task_1_output_accuracy'])), history.history['task_1_output_accuracy'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_accuracy'])), history.history['task_2_output_accuracy'], c='b', label='Task 2')\n",
        "        plt.plot(range(len(history.history['task_1_output_precision'])), history.history['task_1_output_precision'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_precision'])), history.history['task_2_output_precision'], c='b', label='Task 2')\n",
        "        plt.plot(range(len(history.history['task_1_output_recall'])), history.history['task_1_output_recall'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_recall'])), history.history['task_2_output_recall'], c='b', label='Task 2')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        counter += 1\n",
        "\n",
        "\"\"\"Actually training the model\"\"\"\n",
        "#gamma_values = [ [0.2, 0.2, 0.2, 0.2, 0.2],\n",
        "#                [0.8, 0.1, 0.0333, 0.0333, 0.0333],\n",
        "#                [0.5, 0.125, 0.125, 0.125, 0.125],\n",
        "#                [0.5, 0.2, 0.1, 0.1, 0.1],\n",
        "#                [0.6, 0.3, 0.033, 0.033, 0.033]]\n",
        "\n",
        "gamma_values = [  #[0.5, 0.25, 0.25, 0, 0],\n",
        "                  #[0.6, 0.2, 0.2, 0, 0],\n",
        "                  [0.7, 0.2, 0.1, 0, 0],\n",
        "                  #[0.8, 0.1, 0.1, 0, 0],\n",
        "                  ]\n",
        "\n",
        "history, trained_models, _ = fit_batch(gamma_values, epochs=50, save_models=True, models_dir=\"./trained_models_sixth_augmentation\", verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coR9RTvap_UF",
        "outputId": "c253e764-c845-4513-9d46-ba02a327b731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training on batch of models for gamma values  [[0.7, 0.2, 0.1, 0, 0]] \n",
            "\n",
            "\n",
            "Training model for gamma equal to  [0.7, 0.2, 0.1, 0, 0]\n",
            "Epoch 1/50\n",
            "769/769 [==============================] - 108s 76ms/step - loss: 0.4549 - task_1_output_loss: 0.3216 - task_2_output_loss: 1.1296 - task_3_output_loss: 0.0387 - task_1_output_accuracy: 0.9526 - task_1_output_precision_6: 0.9526 - task_1_output_recall_6: 0.9526 - task_2_output_accuracy: 0.8014 - task_2_output_precision_7: 0.8613 - task_2_output_recall_7: 0.3931 - task_3_output_mse: 0.0387\n",
            "Epoch 2/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.2129 - task_1_output_loss: 0.1170 - task_2_output_loss: 0.6404 - task_3_output_loss: 0.0291 - task_1_output_accuracy: 0.9866 - task_1_output_precision_6: 0.9866 - task_1_output_recall_6: 0.9866 - task_2_output_accuracy: 0.8406 - task_2_output_precision_7: 0.8823 - task_2_output_recall_7: 0.7978 - task_3_output_mse: 0.0291\n",
            "Epoch 3/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.1536 - task_1_output_loss: 0.0709 - task_2_output_loss: 0.5138 - task_3_output_loss: 0.0117 - task_1_output_accuracy: 0.9915 - task_1_output_precision_6: 0.9915 - task_1_output_recall_6: 0.9915 - task_2_output_accuracy: 0.8536 - task_2_output_precision_7: 0.9064 - task_2_output_recall_7: 0.8179 - task_3_output_mse: 0.0117\n",
            "Epoch 4/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.1208 - task_1_output_loss: 0.0474 - task_2_output_loss: 0.4359 - task_3_output_loss: 0.0048 - task_1_output_accuracy: 0.9945 - task_1_output_precision_6: 0.9945 - task_1_output_recall_6: 0.9945 - task_2_output_accuracy: 0.8765 - task_2_output_precision_7: 0.9297 - task_2_output_recall_7: 0.8250 - task_3_output_mse: 0.0048\n",
            "Epoch 5/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.1070 - task_1_output_loss: 0.0401 - task_2_output_loss: 0.3931 - task_3_output_loss: 0.0028 - task_1_output_accuracy: 0.9943 - task_1_output_precision_6: 0.9943 - task_1_output_recall_6: 0.9943 - task_2_output_accuracy: 0.8879 - task_2_output_precision_7: 0.9398 - task_2_output_recall_7: 0.8441 - task_3_output_mse: 0.0028\n",
            "Epoch 6/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0964 - task_1_output_loss: 0.0349 - task_2_output_loss: 0.3592 - task_3_output_loss: 0.0017 - task_1_output_accuracy: 0.9944 - task_1_output_precision_6: 0.9944 - task_1_output_recall_6: 0.9944 - task_2_output_accuracy: 0.8953 - task_2_output_precision_7: 0.9437 - task_2_output_recall_7: 0.8614 - task_3_output_mse: 0.0017\n",
            "Epoch 7/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0784 - task_1_output_loss: 0.0242 - task_2_output_loss: 0.3073 - task_3_output_loss: 7.9228e-04 - task_1_output_accuracy: 0.9969 - task_1_output_precision_6: 0.9969 - task_1_output_recall_6: 0.9969 - task_2_output_accuracy: 0.9074 - task_2_output_precision_7: 0.9547 - task_2_output_recall_7: 0.8726 - task_3_output_mse: 7.9228e-04\n",
            "Epoch 8/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0752 - task_1_output_loss: 0.0227 - task_2_output_loss: 0.2966 - task_3_output_loss: 3.5049e-04 - task_1_output_accuracy: 0.9962 - task_1_output_precision_6: 0.9962 - task_1_output_recall_6: 0.9962 - task_2_output_accuracy: 0.9092 - task_2_output_precision_7: 0.9567 - task_2_output_recall_7: 0.8760 - task_3_output_mse: 3.5049e-04\n",
            "Epoch 9/50\n",
            "769/769 [==============================] - 57s 75ms/step - loss: 0.0646 - task_1_output_loss: 0.0172 - task_2_output_loss: 0.2629 - task_3_output_loss: 1.4236e-04 - task_1_output_accuracy: 0.9972 - task_1_output_precision_6: 0.9972 - task_1_output_recall_6: 0.9972 - task_2_output_accuracy: 0.9165 - task_2_output_precision_7: 0.9632 - task_2_output_recall_7: 0.8843 - task_3_output_mse: 1.4236e-04\n",
            "Epoch 10/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0577 - task_1_output_loss: 0.0140 - task_2_output_loss: 0.2395 - task_3_output_loss: 8.2232e-05 - task_1_output_accuracy: 0.9977 - task_1_output_precision_6: 0.9977 - task_1_output_recall_6: 0.9977 - task_2_output_accuracy: 0.9202 - task_2_output_precision_7: 0.9679 - task_2_output_recall_7: 0.8901 - task_3_output_mse: 8.2232e-05\n",
            "Epoch 11/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0545 - task_1_output_loss: 0.0133 - task_2_output_loss: 0.2263 - task_3_output_loss: 3.5085e-05 - task_1_output_accuracy: 0.9973 - task_1_output_precision_6: 0.9973 - task_1_output_recall_6: 0.9973 - task_2_output_accuracy: 0.9228 - task_2_output_precision_7: 0.9708 - task_2_output_recall_7: 0.8939 - task_3_output_mse: 3.5085e-05\n",
            "Epoch 12/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0498 - task_1_output_loss: 0.0100 - task_2_output_loss: 0.2141 - task_3_output_loss: 1.4448e-05 - task_1_output_accuracy: 0.9982 - task_1_output_precision_6: 0.9982 - task_1_output_recall_6: 0.9982 - task_2_output_accuracy: 0.9267 - task_2_output_precision_7: 0.9727 - task_2_output_recall_7: 0.8969 - task_3_output_mse: 1.4448e-05\n",
            "Epoch 13/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0480 - task_1_output_loss: 0.0101 - task_2_output_loss: 0.2047 - task_3_output_loss: 1.1007e-05 - task_1_output_accuracy: 0.9983 - task_1_output_precision_6: 0.9983 - task_1_output_recall_6: 0.9983 - task_2_output_accuracy: 0.9292 - task_2_output_precision_7: 0.9737 - task_2_output_recall_7: 0.9004 - task_3_output_mse: 1.1007e-05\n",
            "Epoch 14/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0474 - task_1_output_loss: 0.0103 - task_2_output_loss: 0.2009 - task_3_output_loss: 3.6925e-06 - task_1_output_accuracy: 0.9978 - task_1_output_precision_6: 0.9978 - task_1_output_recall_6: 0.9978 - task_2_output_accuracy: 0.9305 - task_2_output_precision_7: 0.9724 - task_2_output_recall_7: 0.9006 - task_3_output_mse: 3.6925e-06\n",
            "Epoch 15/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0466 - task_1_output_loss: 0.0105 - task_2_output_loss: 0.1963 - task_3_output_loss: 2.4350e-06 - task_1_output_accuracy: 0.9979 - task_1_output_precision_6: 0.9979 - task_1_output_recall_6: 0.9979 - task_2_output_accuracy: 0.9294 - task_2_output_precision_7: 0.9719 - task_2_output_recall_7: 0.9018 - task_3_output_mse: 2.4350e-06\n",
            "Epoch 16/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0387 - task_1_output_loss: 0.0057 - task_2_output_loss: 0.1734 - task_3_output_loss: 2.0687e-06 - task_1_output_accuracy: 0.9992 - task_1_output_precision_6: 0.9992 - task_1_output_recall_6: 0.9992 - task_2_output_accuracy: 0.9369 - task_2_output_precision_7: 0.9773 - task_2_output_recall_7: 0.9072 - task_3_output_mse: 2.0687e-06\n",
            "Epoch 17/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0377 - task_1_output_loss: 0.0050 - task_2_output_loss: 0.1712 - task_3_output_loss: 1.9301e-06 - task_1_output_accuracy: 0.9991 - task_1_output_precision_6: 0.9991 - task_1_output_recall_6: 0.9991 - task_2_output_accuracy: 0.9350 - task_2_output_precision_7: 0.9758 - task_2_output_recall_7: 0.9064 - task_3_output_mse: 1.9301e-06\n",
            "Epoch 18/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0387 - task_1_output_loss: 0.0068 - task_2_output_loss: 0.1696 - task_3_output_loss: 1.8280e-06 - task_1_output_accuracy: 0.9987 - task_1_output_precision_6: 0.9987 - task_1_output_recall_6: 0.9987 - task_2_output_accuracy: 0.9351 - task_2_output_precision_7: 0.9768 - task_2_output_recall_7: 0.9064 - task_3_output_mse: 1.8280e-06\n",
            "Epoch 19/50\n",
            "769/769 [==============================] - 60s 78ms/step - loss: 0.0376 - task_1_output_loss: 0.0065 - task_2_output_loss: 0.1650 - task_3_output_loss: 1.8388e-06 - task_1_output_accuracy: 0.9987 - task_1_output_precision_6: 0.9987 - task_1_output_recall_6: 0.9987 - task_2_output_accuracy: 0.9367 - task_2_output_precision_7: 0.9766 - task_2_output_recall_7: 0.9071 - task_3_output_mse: 1.8388e-06\n",
            "Epoch 20/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0389 - task_1_output_loss: 0.0075 - task_2_output_loss: 0.1684 - task_3_output_loss: 1.8043e-06 - task_1_output_accuracy: 0.9984 - task_1_output_precision_6: 0.9984 - task_1_output_recall_6: 0.9984 - task_2_output_accuracy: 0.9364 - task_2_output_precision_7: 0.9769 - task_2_output_recall_7: 0.9054 - task_3_output_mse: 1.8043e-06\n",
            "Epoch 21/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0328 - task_1_output_loss: 0.0033 - task_2_output_loss: 0.1528 - task_3_output_loss: 1.7984e-06 - task_1_output_accuracy: 0.9996 - task_1_output_precision_6: 0.9996 - task_1_output_recall_6: 0.9996 - task_2_output_accuracy: 0.9387 - task_2_output_precision_7: 0.9789 - task_2_output_recall_7: 0.9085 - task_3_output_mse: 1.7984e-06\n",
            "Epoch 22/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0324 - task_1_output_loss: 0.0048 - task_2_output_loss: 0.1455 - task_3_output_loss: 1.7976e-06 - task_1_output_accuracy: 0.9991 - task_1_output_precision_6: 0.9991 - task_1_output_recall_6: 0.9991 - task_2_output_accuracy: 0.9407 - task_2_output_precision_7: 0.9797 - task_2_output_recall_7: 0.9096 - task_3_output_mse: 1.7976e-06\n",
            "Epoch 23/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0327 - task_1_output_loss: 0.0040 - task_2_output_loss: 0.1498 - task_3_output_loss: 1.7974e-06 - task_1_output_accuracy: 0.9991 - task_1_output_precision_6: 0.9991 - task_1_output_recall_6: 0.9991 - task_2_output_accuracy: 0.9404 - task_2_output_precision_7: 0.9785 - task_2_output_recall_7: 0.9080 - task_3_output_mse: 1.7974e-06\n",
            "Epoch 24/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0343 - task_1_output_loss: 0.0059 - task_2_output_loss: 0.1506 - task_3_output_loss: 1.8025e-06 - task_1_output_accuracy: 0.9989 - task_1_output_precision_6: 0.9989 - task_1_output_recall_6: 0.9989 - task_2_output_accuracy: 0.9403 - task_2_output_precision_7: 0.9762 - task_2_output_recall_7: 0.9094 - task_3_output_mse: 1.8025e-06\n",
            "Epoch 25/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0274 - task_1_output_loss: 0.0025 - task_2_output_loss: 0.1280 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9996 - task_1_output_precision_6: 0.9996 - task_1_output_recall_6: 0.9996 - task_2_output_accuracy: 0.9487 - task_2_output_precision_7: 0.9803 - task_2_output_recall_7: 0.9167 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 26/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0324 - task_1_output_loss: 0.0066 - task_2_output_loss: 0.1386 - task_3_output_loss: 1.8019e-06 - task_1_output_accuracy: 0.9986 - task_1_output_precision_6: 0.9986 - task_1_output_recall_6: 0.9986 - task_2_output_accuracy: 0.9501 - task_2_output_precision_7: 0.9756 - task_2_output_recall_7: 0.9220 - task_3_output_mse: 1.8019e-06\n",
            "Epoch 27/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0258 - task_1_output_loss: 0.0030 - task_2_output_loss: 0.1185 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9996 - task_1_output_precision_6: 0.9996 - task_1_output_recall_6: 0.9996 - task_2_output_accuracy: 0.9600 - task_2_output_precision_7: 0.9782 - task_2_output_recall_7: 0.9365 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 28/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0258 - task_1_output_loss: 0.0043 - task_2_output_loss: 0.1142 - task_3_output_loss: 1.8322e-06 - task_1_output_accuracy: 0.9992 - task_1_output_precision_6: 0.9992 - task_1_output_recall_6: 0.9992 - task_2_output_accuracy: 0.9641 - task_2_output_precision_7: 0.9776 - task_2_output_recall_7: 0.9443 - task_3_output_mse: 1.8322e-06\n",
            "Epoch 29/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0306 - task_1_output_loss: 0.0094 - task_2_output_loss: 0.1201 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9980 - task_1_output_precision_6: 0.9980 - task_1_output_recall_6: 0.9980 - task_2_output_accuracy: 0.9610 - task_2_output_precision_7: 0.9745 - task_2_output_recall_7: 0.9444 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 30/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0221 - task_1_output_loss: 0.0032 - task_2_output_loss: 0.0996 - task_3_output_loss: 1.9264e-06 - task_1_output_accuracy: 0.9996 - task_1_output_precision_6: 0.9996 - task_1_output_recall_6: 0.9996 - task_2_output_accuracy: 0.9683 - task_2_output_precision_7: 0.9781 - task_2_output_recall_7: 0.9562 - task_3_output_mse: 1.9264e-06\n",
            "Epoch 31/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0296 - task_1_output_loss: 0.0091 - task_2_output_loss: 0.1163 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9979 - task_1_output_precision_6: 0.9979 - task_1_output_recall_6: 0.9979 - task_2_output_accuracy: 0.9608 - task_2_output_precision_7: 0.9732 - task_2_output_recall_7: 0.9499 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 32/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0207 - task_1_output_loss: 0.0042 - task_2_output_loss: 0.0889 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9993 - task_1_output_precision_6: 0.9993 - task_1_output_recall_6: 0.9993 - task_2_output_accuracy: 0.9699 - task_2_output_precision_7: 0.9788 - task_2_output_recall_7: 0.9612 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 33/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0200 - task_1_output_loss: 0.0033 - task_2_output_loss: 0.0885 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9995 - task_1_output_precision_6: 0.9995 - task_1_output_recall_6: 0.9995 - task_2_output_accuracy: 0.9699 - task_2_output_precision_7: 0.9792 - task_2_output_recall_7: 0.9609 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 34/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0209 - task_1_output_loss: 0.0038 - task_2_output_loss: 0.0910 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9994 - task_1_output_precision_6: 0.9994 - task_1_output_recall_6: 0.9994 - task_2_output_accuracy: 0.9694 - task_2_output_precision_7: 0.9774 - task_2_output_recall_7: 0.9617 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 35/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0175 - task_1_output_loss: 0.0020 - task_2_output_loss: 0.0803 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9997 - task_1_output_precision_6: 0.9997 - task_1_output_recall_6: 0.9997 - task_2_output_accuracy: 0.9716 - task_2_output_precision_7: 0.9801 - task_2_output_recall_7: 0.9644 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 36/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0204 - task_1_output_loss: 0.0048 - task_2_output_loss: 0.0849 - task_3_output_loss: 1.8226e-06 - task_1_output_accuracy: 0.9989 - task_1_output_precision_6: 0.9989 - task_1_output_recall_6: 0.9989 - task_2_output_accuracy: 0.9704 - task_2_output_precision_7: 0.9788 - task_2_output_recall_7: 0.9629 - task_3_output_mse: 1.8226e-06\n",
            "Epoch 37/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0143 - task_1_output_loss: 0.0016 - task_2_output_loss: 0.0658 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 1.0000 - task_1_output_precision_6: 1.0000 - task_1_output_recall_6: 1.0000 - task_2_output_accuracy: 0.9749 - task_2_output_precision_7: 0.9829 - task_2_output_recall_7: 0.9679 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 38/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0192 - task_1_output_loss: 0.0052 - task_2_output_loss: 0.0777 - task_3_output_loss: 1.8074e-06 - task_1_output_accuracy: 0.9991 - task_1_output_precision_6: 0.9991 - task_1_output_recall_6: 0.9991 - task_2_output_accuracy: 0.9728 - task_2_output_precision_7: 0.9813 - task_2_output_recall_7: 0.9658 - task_3_output_mse: 1.8074e-06\n",
            "Epoch 39/50\n",
            "769/769 [==============================] - 60s 78ms/step - loss: 0.0165 - task_1_output_loss: 0.0048 - task_2_output_loss: 0.0660 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9991 - task_1_output_precision_6: 0.9991 - task_1_output_recall_6: 0.9991 - task_2_output_accuracy: 0.9778 - task_2_output_precision_7: 0.9848 - task_2_output_recall_7: 0.9703 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 40/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0155 - task_1_output_loss: 0.0036 - task_2_output_loss: 0.0649 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9992 - task_1_output_precision_6: 0.9992 - task_1_output_recall_6: 0.9992 - task_2_output_accuracy: 0.9786 - task_2_output_precision_7: 0.9856 - task_2_output_recall_7: 0.9720 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 41/50\n",
            "769/769 [==============================] - 58s 75ms/step - loss: 0.0133 - task_1_output_loss: 0.0021 - task_2_output_loss: 0.0590 - task_3_output_loss: 1.8106e-06 - task_1_output_accuracy: 0.9998 - task_1_output_precision_6: 0.9998 - task_1_output_recall_6: 0.9998 - task_2_output_accuracy: 0.9823 - task_2_output_precision_7: 0.9869 - task_2_output_recall_7: 0.9765 - task_3_output_mse: 1.8106e-06\n",
            "Epoch 42/50\n",
            "769/769 [==============================] - 58s 76ms/step - loss: 0.0206 - task_1_output_loss: 0.0077 - task_2_output_loss: 0.0760 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9987 - task_1_output_precision_6: 0.9987 - task_1_output_recall_6: 0.9987 - task_2_output_accuracy: 0.9772 - task_2_output_precision_7: 0.9841 - task_2_output_recall_7: 0.9715 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 43/50\n",
            "769/769 [==============================] - 60s 78ms/step - loss: 0.0150 - task_1_output_loss: 0.0043 - task_2_output_loss: 0.0599 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9989 - task_1_output_precision_6: 0.9989 - task_1_output_recall_6: 0.9989 - task_2_output_accuracy: 0.9813 - task_2_output_precision_7: 0.9867 - task_2_output_recall_7: 0.9752 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 44/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0117 - task_1_output_loss: 0.0029 - task_2_output_loss: 0.0484 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9995 - task_1_output_precision_6: 0.9995 - task_1_output_recall_6: 0.9995 - task_2_output_accuracy: 0.9858 - task_2_output_precision_7: 0.9904 - task_2_output_recall_7: 0.9794 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 45/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0104 - task_1_output_loss: 0.0023 - task_2_output_loss: 0.0440 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9996 - task_1_output_precision_6: 0.9996 - task_1_output_recall_6: 0.9996 - task_2_output_accuracy: 0.9863 - task_2_output_precision_7: 0.9910 - task_2_output_recall_7: 0.9815 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 46/50\n",
            "769/769 [==============================] - 60s 77ms/step - loss: 0.0137 - task_1_output_loss: 0.0045 - task_2_output_loss: 0.0529 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9990 - task_1_output_precision_6: 0.9990 - task_1_output_recall_6: 0.9990 - task_2_output_accuracy: 0.9835 - task_2_output_precision_7: 0.9883 - task_2_output_recall_7: 0.9785 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 47/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0107 - task_1_output_loss: 0.0026 - task_2_output_loss: 0.0441 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9997 - task_1_output_precision_6: 0.9997 - task_1_output_recall_6: 0.9997 - task_2_output_accuracy: 0.9865 - task_2_output_precision_7: 0.9907 - task_2_output_recall_7: 0.9816 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 48/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0148 - task_1_output_loss: 0.0048 - task_2_output_loss: 0.0572 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9988 - task_1_output_precision_6: 0.9988 - task_1_output_recall_6: 0.9988 - task_2_output_accuracy: 0.9822 - task_2_output_precision_7: 0.9869 - task_2_output_recall_7: 0.9777 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 49/50\n",
            "769/769 [==============================] - 59s 76ms/step - loss: 0.0101 - task_1_output_loss: 0.0015 - task_2_output_loss: 0.0454 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9997 - task_1_output_precision_6: 0.9997 - task_1_output_recall_6: 0.9997 - task_2_output_accuracy: 0.9856 - task_2_output_precision_7: 0.9892 - task_2_output_recall_7: 0.9812 - task_3_output_mse: 1.7973e-06\n",
            "Epoch 50/50\n",
            "769/769 [==============================] - 59s 77ms/step - loss: 0.0123 - task_1_output_loss: 0.0043 - task_2_output_loss: 0.0465 - task_3_output_loss: 1.7973e-06 - task_1_output_accuracy: 0.9987 - task_1_output_precision_6: 0.9987 - task_1_output_recall_6: 0.9987 - task_2_output_accuracy: 0.9871 - task_2_output_precision_7: 0.9909 - task_2_output_recall_7: 0.9822 - task_3_output_mse: 1.7973e-06\n",
            "Training time: 2986.854040622711\n",
            "\n",
            "176/176 [==============================] - 7s 24ms/step - loss: 3.1940 - task_1_output_loss: 3.3003 - task_2_output_loss: 4.4189 - task_3_output_loss: 1.4901e-06 - task_1_output_accuracy: 0.4009 - task_1_output_precision_6: 0.4009 - task_1_output_recall_6: 0.4009 - task_2_output_accuracy: 0.2231 - task_2_output_precision_7: 0.2221 - task_2_output_recall_7: 0.2140 - task_3_output_mse: 1.4901e-06\n",
            "loss: 3.1939537525177\n",
            "task_1_output_loss: 3.3002564907073975\n",
            "task_2_output_loss: 4.4188737869262695\n",
            "task_3_output_loss: 1.4901063423167216e-06\n",
            "task_1_output_accuracy: 0.4008888900279999\n",
            "task_1_output_precision_6: 0.4008888900279999\n",
            "task_1_output_recall_6: 0.4008888900279999\n",
            "task_2_output_accuracy: 0.2231111079454422\n",
            "task_2_output_precision_7: 0.22214022278785706\n",
            "task_2_output_recall_7: 0.214044451713562\n",
            "task_3_output_mse: 1.4901063423167216e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ZNCyhFlwoZ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
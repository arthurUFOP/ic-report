{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Credits to https://towardsdatascience.com/multi-task-learning-for-computer-vision-classification-with-keras-36c52e6243d2\n",
        "#            https://github.com/GATECH-EIC/TinyML-Contest-Solution"
      ],
      "metadata": {
        "id": "imR900TVDror"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m4wIvdbm2QJ"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import time\n",
        "import os\n",
        "import csv\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Functions for loading data \"\"\"\n",
        "def txt_to_numpy(filename, row=1250):\n",
        "    file = open(filename)\n",
        "    lines = file.readlines()\n",
        "    datamat = np.arange(row, dtype=np.float)\n",
        "    row_count = 0\n",
        "    for line in lines:\n",
        "        line = line.strip().split(' ')\n",
        "        datamat[row_count] = line[0]\n",
        "        row_count += 1\n",
        "\n",
        "    return datamat\n",
        "\n",
        "\"\"\"\n",
        "AFb,Atrial Fibrillation\n",
        "AFt,Atrial Flutter\n",
        "SR,Sinus Rhythm\n",
        "SVT,Supraventricular Tachycardia\n",
        "VFb,Ventricular Fibrillation\n",
        "VFt,Ventricular Flutter\n",
        "VPD,Ventricular Premature Depolarizations\n",
        "VT,Ventricular Tachycardia\n",
        "\"\"\"\n",
        "def txt_to_disease_type(txt):\n",
        "    txt = txt.upper()\n",
        "    if txt == \"AFb\":\n",
        "      return [1, 0, 0, 0, 0, 0, 0, 0]\n",
        "    if txt == \"AFT\":\n",
        "      return [0, 1, 0, 0, 0, 0, 0, 0]\n",
        "    if txt == \"SR\":\n",
        "      return [0, 0, 1, 0, 0, 0, 0, 0]\n",
        "    if txt == \"SVT\":\n",
        "      return [0, 0, 0, 1, 0, 0, 0, 0]\n",
        "    if txt == \"VFB\":\n",
        "      return [0, 0, 0, 0, 1, 0, 0, 0]\n",
        "    if txt == \"VFT\":\n",
        "      return [0, 0, 0, 0, 0, 1, 0, 0]\n",
        "    if txt == \"VPD\":\n",
        "      return [0, 0, 0, 0, 0, 0, 1, 0]\n",
        "    if txt == \"VT\":\n",
        "      return [0, 0, 0, 0, 0, 0, 0, 1]\n",
        "    raise \"A string was not recognized as a valid input on txt_to_disease_type func!\"\n",
        "\n",
        "\n",
        "def read_data(csv_path, imgs_folder=\"./tinyml_contest_data_training\", augmentation=False, flip_peak=False, flip_time=False, add_noise=False):\n",
        "    x, y1, y2 = [], [], []\n",
        "    with open(csv_path, \"r\") as csv_file:\n",
        "      reader = csv.reader(csv_file)\n",
        "      next(reader)\n",
        "      for item in reader: # item[0] = label; item[1] = filename\n",
        "        x.append(txt_to_numpy(os.path.join(imgs_folder, item[1]), 1250))\n",
        "        y1.append([1, 0] if int(item[0]) == 0 else [0, 1]) # Label for life threat\n",
        "        y2.append(txt_to_disease_type(item[1].split(\"-\")[1]))\n",
        "    x, y1, y2 = sklearn.utils.shuffle(x, y1, y2)\n",
        "    if augmentation:\n",
        "      for i in range(len(x)):\n",
        "        flip_p = random.random()\n",
        "        flip_t = random.random()\n",
        "        if flip_p < 0.5 and flip_peak:\n",
        "          x[i] = -x[i]\n",
        "        if flip_t < 0.5 and flip_time:\n",
        "          x[i] = np.flip(x[i])\n",
        "        if add_noise:\n",
        "          max_peak = x[i].max() * 0.05\n",
        "          factor = random.random()\n",
        "          # factor = 1\n",
        "          noise = np.random.normal(0, factor * max_peak, (len(x[i]), 1))\n",
        "          x[i] = x[i] + noise\n",
        "    return x, y1, y2\n"
      ],
      "metadata": {
        "id": "aNwGYa6lKN69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Loading data \"\"\"\n",
        "x_train, y_train_1, y_train_2 = read_data(\"./train_indice.csv\")\n",
        "x_test, y_test_1, y_test_2 = read_data(\"./test_indice.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AApYa_LwEsfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Functions for creating, compiling and training model\"\"\"\n",
        "\n",
        "# Architecture:\n",
        "# Main branch\n",
        "# Branch1 => Decides wheter life threatening (VF or VT style) or not (SR and others)\n",
        "# Branch2 => Classify the input\n",
        "\n",
        "\n",
        "# labels,Rhythm\n",
        "# AFb,Atrial Fibrillation\n",
        "# AFt,Atrial Flutter\n",
        "# SR,Sinus Rhythm\n",
        "# SVT,Supraventricular Tachycardia\n",
        "# VFb,Ventricular Fibrillation\n",
        "# VFt,Ventricular Flutter\n",
        "# VPD,Ventricular Premature Depolarizations\n",
        "# VT,Ventricular Tachycardia\n",
        "\n",
        "\n",
        "def gen_model():\n",
        "    inputs = keras.layers.Input(shape=(1250, 1), name='input')\n",
        "\n",
        "    main_branch = keras.layers.Conv1D(filters=128, kernel_size=20, strides=32, activation=\"relu\") (inputs)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Conv1D(filters=64, kernel_size=20, strides=32, activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Conv1D(filters=32, kernel_size=20, strides=32, activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.BatchNormalization() (main_branch)\n",
        "    main_branch = keras.layers.Flatten() (main_branch)\n",
        "    main_branch = keras.layers.Dropout(0.3) (main_branch)\n",
        "    main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.Dropout(0.1) (main_branch)\n",
        "    main_branch = keras.layers.Dense(512, activation=\"relu\") (main_branch)\n",
        "    main_branch = keras.layers.Dropout(0.1) (main_branch)\n",
        "\n",
        "    # Decides wheter life threatening (VF or VT style) or not (SR and others)\n",
        "    branch1 = keras.layers.Dense(128, activation=\"relu\") (main_branch)\n",
        "    branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    branch1 = keras.layers.Dense(128, activation=\"relu\") (branch1)\n",
        "    branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    branch1 = keras.layers.Dense(128, activation=\"relu\") (branch1)\n",
        "    branch1 = keras.layers.BatchNormalization() (branch1)\n",
        "    branch1 = keras.layers.Dropout(0.2) (branch1)\n",
        "    branch1 = keras.layers.Dense(2, activation=\"softmax\", name='task_1_output') (branch1)\n",
        "\n",
        "    # Classify the input\n",
        "    branch2 = keras.layers.Dense(128, activation=\"relu\") (main_branch)\n",
        "    branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    branch2 = keras.layers.Dense(128, activation=\"relu\") (branch2)\n",
        "    branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    branch2 = keras.layers.Dense(128, activation=\"relu\") (branch2)\n",
        "    branch2 = keras.layers.BatchNormalization() (branch2)\n",
        "    branch2 = keras.layers.Dropout(0.2) (branch2)\n",
        "    branch2 = keras.layers.Dense(8, activation=\"softmax\", name='task_2_output') (branch2)\n",
        "\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = [branch1, branch2])\n",
        "\n",
        "    return model\n",
        "\n",
        "# loss_weight -> [0, 1]\n",
        "# the weight for the second task is calculated by '1 - loss_weight'\n",
        "def compile_model(model, loss_weight):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss={'task_1_output': 'binary_crossentropy',\n",
        "                        'task_2_output': 'categorical_crossentropy'},\n",
        "                  loss_weights={'task_1_output': loss_weight,\n",
        "                                'task_2_output': 1 - loss_weight},\n",
        "                  metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "    return model\n",
        "\n",
        "def fit_batch(gamma_values, epochs=30, batch_size=32, save_models=False, models_dir=\"./trained_models\", verbose=0):\n",
        "\n",
        "    history = list()\n",
        "    trained_models = list()\n",
        "    test_scores = list()\n",
        "\n",
        "    if save_models:\n",
        "      os.mkdir(models_dir)\n",
        "\n",
        "    print('Starting training on batch of models for gamma values ', gamma_values, '\\n\\n')\n",
        "\n",
        "    for i, gamma in enumerate(gamma_values):\n",
        "\n",
        "        print('Training model for gamma equal to ', gamma)\n",
        "        model = gen_model()\n",
        "        model = compile_model(model, gamma)\n",
        "        start = time.time()\n",
        "        model_history = model.fit({'input': x_train},\n",
        "                            {'task_1_output': y_train_1, 'task_2_output': y_train_2},\n",
        "                            epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "        print(f'Training time: {time.time() - start}\\n')\n",
        "        history.append(model_history)\n",
        "        trained_models.append(model)\n",
        "        if save_models:\n",
        "          model.save(os.path.join(models_dir, f\"{i}th-model\"))\n",
        "\n",
        "        test_score = model.evaluate({'input': x_test}, {'task_1_output': y_test_1, 'task_2_output': y_test_2})\n",
        "        print(\"Results:\", test_score)\n",
        "        print(\"Metrics:\", model.metrics_names)\n",
        "\n",
        "        test_scores.append(test_score)\n",
        "\n",
        "    return history, trained_models, test_scores"
      ],
      "metadata": {
        "id": "CUCWpc1Pm5bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_multitask_accuracies(gammas, training_history):\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for history in training_history:\n",
        "\n",
        "        print(f'\\nPlotting Accuracy/Precision/Recall vs Epochs for value of gamma number {gammas[counter]}\\n')\n",
        "        plt.plot(range(len(history.history['task_1_output_accuracy'])), history.history['task_1_output_accuracy'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_accuracy'])), history.history['task_2_output_accuracy'], c='b', label='Task 2')\n",
        "        plt.plot(range(len(history.history['task_1_output_precision'])), history.history['task_1_output_precision'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_precision'])), history.history['task_2_output_precision'], c='b', label='Task 2')\n",
        "        plt.plot(range(len(history.history['task_1_output_recall'])), history.history['task_1_output_recall'], c='r', label='Task 1')\n",
        "        plt.plot(range(len(history.history['task_2_output_recall'])), history.history['task_2_output_recall'], c='b', label='Task 2')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        counter += 1"
      ],
      "metadata": {
        "id": "H2gIkeECBBGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Actually training the model\"\"\"\n",
        "gamma_values = [0.5, 0.6, 0.7, 0.8] # Higher value => Higher importance on class identification, less importance on classifing life-threat\n",
        "\n",
        "history, trained_models, _ = fit_batch(gamma_values, save_models=True, verbose=1)"
      ],
      "metadata": {
        "id": "XrLnc2S0C_A6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}